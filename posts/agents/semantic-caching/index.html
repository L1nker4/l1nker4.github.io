<!DOCTYPE html>
<html lang="en">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  <meta name="generator" content="Hugo 0.145.0">

  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="author" content="" />
  <meta property="og:url" content="http://localhost:1313/posts/agents/semantic-caching/" />
  <link rel="canonical" href="http://localhost:1313/posts/agents/semantic-caching/" /><link rel="apple-touch-icon" href="/favicon.png" />
  <link rel="icon" href="/favicon.png" />
  <link rel="shortcut" href="/favicon.png" /><link rel="alternate" type="application/atom+xml" href="http://localhost:1313/index.xml" title="L1nker4&#39;s Blog | 格木观云">

  <script type="application/ld+json">
  {
      "@context" : "http://schema.org",
      "@type" : "BlogPosting",
      "mainEntityOfPage": {
           "@type": "WebPage",
           "@id": "http:\/\/localhost:1313\/"
      },
      "articleSection" : "posts",
      "name" : "Semantic Caching（语意缓存）：AI应用降本增效利器",
      "headline" : "Semantic Caching（语意缓存）：AI应用降本增效利器",
      "description" : "1. Intro 传统缓存的核心逻辑是精确字符串匹配：将查询作为 key完全一致时命中缓存。这种机制在静态内容分发、API 响应缓存等场景下运作良好，但在AI应用领域的表现较差，相似意图的Query无法精准命中。语义缓存（Semantic Caching）是一种利用Embedding向量化和向量相似度搜索来实现基于语义相似进行缓存匹配的机制。\n语义缓存的工作流程可以概括为四个阶段：\n用户查询 → [1. Embedding 向量化] → [2. 向量相似度搜索] → Hit? → [3. 返回缓存结果] ↓ Miss [4. 调用 LLM → 缓存结果] Embedding 向量化：将用户的自然语言查询通过 Embedding 模型映射为高维向量。这一向量编码了查询的语义信息，使得含义相近的文本在向量空间中彼此接近。 向量相似度搜索 ：将新查询的向量与向量数据库中已存储的缓存向量进行比较，使用余弦距离（Cosine Distance）等度量方式计算语义距离，找出最近邻。 缓存命中判定 ：若最近邻的距离小于预设阈值（如 0.15），则判定为缓存命中，直接返回对应的 LLM 响应。 缓存未命中处理 若无满足阈值条件的缓存结果，则将查询发送至 LLM 获取响应，并将该查询的 Embedding 向量与 LLM 响应一起写入缓存，供后续请求复用。 语义缓存在客服聊天机器人、企业内部知识库等场景中能够发挥显著价值，此类场景大量Query集中在少数高频问题中，使用语意缓存可以显著降低AI应用的token成本。\n2. 基于RedisVL实现语义缓存 2.1. RedisVL介绍 RedisVL（Redis Vector Library） 是 Redis 官方提供的 Python 客户端库，专为 AI 应用场景设计。它在 Redis 核心的高性能数据存储能力之上，封装了向量索引管理、多种 Embedding 模型集成、向量相似度搜索等功能，使开发者无需直接操作底层的 RediSearch 命令即可构建向量检索应用。在语义缓存领域，RedisVL 提供了 SemanticCache 类作为核心抽象，将索引创建、Embedding 向量化、KNN 搜索、阈值判定、TTL 管理等操作封装为简洁的 check() \/ store() API。同时，RedisVL 内置了对 OpenAI、HuggingFace、Cohere 等主流 Embedding Model的适配，并支持 Tag 和 Numeric 过滤实现多租户缓存隔离。\n",
      "inLanguage" : "en-US",
      "author" : "",
      "creator" : "",
      "publisher": "",
      "accountablePerson" : "",
      "copyrightHolder" : "",
      "copyrightYear" : "2026",
      "datePublished": "2026-02-01 15:41:39 \u002b0800 CST",
      "dateModified" : "2026-02-01 15:41:39 \u002b0800 CST",
      "url" : "http:\/\/localhost:1313\/posts\/agents\/semantic-caching\/",
      "keywords" : [  ]
  }
</script>
<title>Semantic Caching（语意缓存）：AI应用降本增效利器</title>
  <meta property="og:title" content="Semantic Caching（语意缓存）：AI应用降本增效利器" />
  <meta property="og:type" content="article" />
  <meta property="og:description" content="1. Intro 传统缓存的核心逻辑是精确字符串匹配：将查询作为 key完全一致时命中缓存。这种机制在静态内容分发、API 响应缓存等场景下运作良好，但在AI应用领域的表现较差，相似意图的Query无法精准命中。语义缓存（Semantic Caching）是一种利用Embedding向量化和向量相似度搜索来实现基于语义相似进行缓存匹配的机制。
语义缓存的工作流程可以概括为四个阶段：
用户查询 → [1. Embedding 向量化] → [2. 向量相似度搜索] → Hit? → [3. 返回缓存结果] ↓ Miss [4. 调用 LLM → 缓存结果] Embedding 向量化：将用户的自然语言查询通过 Embedding 模型映射为高维向量。这一向量编码了查询的语义信息，使得含义相近的文本在向量空间中彼此接近。 向量相似度搜索 ：将新查询的向量与向量数据库中已存储的缓存向量进行比较，使用余弦距离（Cosine Distance）等度量方式计算语义距离，找出最近邻。 缓存命中判定 ：若最近邻的距离小于预设阈值（如 0.15），则判定为缓存命中，直接返回对应的 LLM 响应。 缓存未命中处理 若无满足阈值条件的缓存结果，则将查询发送至 LLM 获取响应，并将该查询的 Embedding 向量与 LLM 响应一起写入缓存，供后续请求复用。 语义缓存在客服聊天机器人、企业内部知识库等场景中能够发挥显著价值，此类场景大量Query集中在少数高频问题中，使用语意缓存可以显著降低AI应用的token成本。
2. 基于RedisVL实现语义缓存 2.1. RedisVL介绍 RedisVL（Redis Vector Library） 是 Redis 官方提供的 Python 客户端库，专为 AI 应用场景设计。它在 Redis 核心的高性能数据存储能力之上，封装了向量索引管理、多种 Embedding 模型集成、向量相似度搜索等功能，使开发者无需直接操作底层的 RediSearch 命令即可构建向量检索应用。在语义缓存领域，RedisVL 提供了 SemanticCache 类作为核心抽象，将索引创建、Embedding 向量化、KNN 搜索、阈值判定、TTL 管理等操作封装为简洁的 check() / store() API。同时，RedisVL 内置了对 OpenAI、HuggingFace、Cohere 等主流 Embedding Model的适配，并支持 Tag 和 Numeric 过滤实现多租户缓存隔离。
" />
  <meta name="description" content="1. Intro 传统缓存的核心逻辑是精确字符串匹配：将查询作为 key完全一致时命中缓存。这种机制在静态内容分发、API 响应缓存等场景下运作良好，但在AI应用领域的表现较差，相似意图的Query无法精准命中。语义缓存（Semantic Caching）是一种利用Embedding向量化和向量相似度搜索来实现基于语义相似进行缓存匹配的机制。
语义缓存的工作流程可以概括为四个阶段：
用户查询 → [1. Embedding 向量化] → [2. 向量相似度搜索] → Hit? → [3. 返回缓存结果] ↓ Miss [4. 调用 LLM → 缓存结果] Embedding 向量化：将用户的自然语言查询通过 Embedding 模型映射为高维向量。这一向量编码了查询的语义信息，使得含义相近的文本在向量空间中彼此接近。 向量相似度搜索 ：将新查询的向量与向量数据库中已存储的缓存向量进行比较，使用余弦距离（Cosine Distance）等度量方式计算语义距离，找出最近邻。 缓存命中判定 ：若最近邻的距离小于预设阈值（如 0.15），则判定为缓存命中，直接返回对应的 LLM 响应。 缓存未命中处理 若无满足阈值条件的缓存结果，则将查询发送至 LLM 获取响应，并将该查询的 Embedding 向量与 LLM 响应一起写入缓存，供后续请求复用。 语义缓存在客服聊天机器人、企业内部知识库等场景中能够发挥显著价值，此类场景大量Query集中在少数高频问题中，使用语意缓存可以显著降低AI应用的token成本。
2. 基于RedisVL实现语义缓存 2.1. RedisVL介绍 RedisVL（Redis Vector Library） 是 Redis 官方提供的 Python 客户端库，专为 AI 应用场景设计。它在 Redis 核心的高性能数据存储能力之上，封装了向量索引管理、多种 Embedding 模型集成、向量相似度搜索等功能，使开发者无需直接操作底层的 RediSearch 命令即可构建向量检索应用。在语义缓存领域，RedisVL 提供了 SemanticCache 类作为核心抽象，将索引创建、Embedding 向量化、KNN 搜索、阈值判定、TTL 管理等操作封装为简洁的 check() / store() API。同时，RedisVL 内置了对 OpenAI、HuggingFace、Cohere 等主流 Embedding Model的适配，并支持 Tag 和 Numeric 过滤实现多租户缓存隔离。
" />
  <meta property="og:locale" content="en-us" /><meta property="og:image" content="/favicon.png" />
  

  
    <style>@import "https://cdnjs.cloudflare.com/ajax/libs/lxgw-wenkai-screen-webfont/1.7.0/lxgwwenkaiscreenr.css";body{font-family:lxgw wenkai screen r,sans-serif;-webkit-font-smoothing:antialiased;margin:0 20px}article{max-width:1000px;margin-left:auto;margin-right:auto}a{color:#000;text-decoration:none}a:hover{font-weight:600;text-decoration:underline}.post-ads{margin:50px 0}.markdown-body{font-size:18px}.markdown-body a{text-decoration:underline;text-decoration-color:#000}.markdown-body blockquote{margin:0;padding:0 1em;color:#57606a;border-left:.25em solid #d0d7de}.markdown-body pre{padding:16px;overflow:auto;border-radius:10px}.markdown-body code{padding:.2em .4em;font-size:75%;background-color:#f6f8fa;border-radius:6px}.markdown-body pre>code{padding:0;font-size:75%;background-color:inherit;border:0;font-family:SFMono-Regular,Consolas,Liberation Mono,Menlo,monospace;line-height:1.6}.Chinese .markdown-body{line-height:200%}.site-date-catalog{font-size:2rem}.header-title{font-size:2rem;font-weight:700;margin-top:32px}.header-title a{text-decoration:none}.header-subtitle{color:#666}.header-items{margin:10px 0}.header-item{margin:0 5px}.header-line{width:100%;border-width:2px;border-color:#482936;border-style:solid none none none}.lang-switch{font-weight:600}#posts-list{min-height:600px}.posts-line{font-size:1.2rem;margin:12px 0}.posts-categories{font-size:.8rem;margin:auto;text-align:center}.posts-category{padding:3px 0;border:#000 2px solid;border-radius:5px}.site-footer{margin-top:50px}.site-footer-item{margin-right:12px}.post-header{margin-bottom:50px}.post-title{font-size:2rem;font-weight:600}.post-tags{display:inline;font-weight:600;padding:2px 5px;margin-right:6px;border:#000 2px solid;border-radius:5px}.post-date{font-weight:800;font-style:italic}.post-author{float:right;font-weight:600}.page-content{min-height:60%}.post-content{margin-bottom:50px}.post-content p{hyphens:auto;line-height:1.8;text-justify:ideographic;margin-bottom:1em}.post-content img{max-width:100%;display:block;margin-right:auto;margin-top:6px}.post-content .post-gallery{display:flex;flex-wrap:wrap;gap:6px}.post-content .post-gallery img{margin-right:auto;margin-top:auto;width:calc(50% - 3px)}.related-content{border-width:3px;border-style:solid;border-color:#000;padding:0 10px;margin-bottom:50px;margin-top:100px}.related-content li{margin:5px 0}.taxonomy-term{font-size:3rem}.gallery-img{text-align:center}.gallery-img span{text-align:center}.gallery-img-desc{font-size:.8em;font-weight:800}#disqus_thread{position:relative}#disqus_thread:after{content:"";display:block;height:55px;width:100%;position:absolute;bottom:0;background:#fff}@media screen and (max-width:600px){.header-title,.header-subtitle,.header-items{}.posts-line{font-size:16px}.markdown-body{font-size:16px}.post-title{font-size:2rem}.post-content p{letter-spacing:.05em}.post-content .post-gallery img{width:100%}}@media screen and (max-width:48em){.posts-category{display:none}}table,th,td{border-collapse:collapse;border-style:solid}.post-content li{line-height:1.8}</style>
  
  
    <style>.container,.container-fluid{margin-right:auto;margin-left:auto}.container-fluid{padding-right:2rem;padding-left:2rem}.row{box-sizing:border-box;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:0;-ms-flex:0 1 auto;flex:initial;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-ms-flex-wrap:wrap;flex-wrap:wrap;margin-right:-.5rem;margin-left:-.5rem}.row.reverse{-webkit-box-orient:horizontal;-webkit-box-direction:reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse}.col.reverse{-webkit-box-orient:vertical;-webkit-box-direction:reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse}.col-xs,.col-xs-1,.col-xs-10,.col-xs-11,.col-xs-12,.col-xs-2,.col-xs-3,.col-xs-4,.col-xs-5,.col-xs-6,.col-xs-7,.col-xs-8,.col-xs-9,.col-xs-offset-0,.col-xs-offset-1,.col-xs-offset-10,.col-xs-offset-11,.col-xs-offset-12,.col-xs-offset-2,.col-xs-offset-3,.col-xs-offset-4,.col-xs-offset-5,.col-xs-offset-6,.col-xs-offset-7,.col-xs-offset-8,.col-xs-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-xs{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-xs-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-xs-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-xs-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-xs-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-xs-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-xs-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-xs-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-xs-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-xs-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-xs-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-xs-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-xs-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-xs-offset-0{margin-left:0}.col-xs-offset-1{margin-left:8.33333333%}.col-xs-offset-2{margin-left:16.66666667%}.col-xs-offset-3{margin-left:25%}.col-xs-offset-4{margin-left:33.33333333%}.col-xs-offset-5{margin-left:41.66666667%}.col-xs-offset-6{margin-left:50%}.col-xs-offset-7{margin-left:58.33333333%}.col-xs-offset-8{margin-left:66.66666667%}.col-xs-offset-9{margin-left:75%}.col-xs-offset-10{margin-left:83.33333333%}.col-xs-offset-11{margin-left:91.66666667%}.start-xs{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-xs{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-xs{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-xs{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-xs{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-xs{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-xs{-ms-flex-pack:distribute;justify-content:space-around}.between-xs{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-xs{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-xs{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}@media only screen and (min-width:48em){.container{width:49rem}.col-sm,.col-sm-1,.col-sm-10,.col-sm-11,.col-sm-12,.col-sm-2,.col-sm-3,.col-sm-4,.col-sm-5,.col-sm-6,.col-sm-7,.col-sm-8,.col-sm-9,.col-sm-offset-0,.col-sm-offset-1,.col-sm-offset-10,.col-sm-offset-11,.col-sm-offset-12,.col-sm-offset-2,.col-sm-offset-3,.col-sm-offset-4,.col-sm-offset-5,.col-sm-offset-6,.col-sm-offset-7,.col-sm-offset-8,.col-sm-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-sm{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-sm-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-sm-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-sm-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-sm-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-sm-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-sm-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-sm-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-sm-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-sm-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-sm-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-sm-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-sm-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-sm-offset-0{margin-left:0}.col-sm-offset-1{margin-left:8.33333333%}.col-sm-offset-2{margin-left:16.66666667%}.col-sm-offset-3{margin-left:25%}.col-sm-offset-4{margin-left:33.33333333%}.col-sm-offset-5{margin-left:41.66666667%}.col-sm-offset-6{margin-left:50%}.col-sm-offset-7{margin-left:58.33333333%}.col-sm-offset-8{margin-left:66.66666667%}.col-sm-offset-9{margin-left:75%}.col-sm-offset-10{margin-left:83.33333333%}.col-sm-offset-11{margin-left:91.66666667%}.start-sm{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-sm{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-sm{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-sm{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-sm{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-sm{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-sm{-ms-flex-pack:distribute;justify-content:space-around}.between-sm{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-sm{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-sm{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}@media only screen and (min-width:64em){.container{width:65rem}.col-md,.col-md-1,.col-md-10,.col-md-11,.col-md-12,.col-md-2,.col-md-3,.col-md-4,.col-md-5,.col-md-6,.col-md-7,.col-md-8,.col-md-9,.col-md-offset-0,.col-md-offset-1,.col-md-offset-10,.col-md-offset-11,.col-md-offset-12,.col-md-offset-2,.col-md-offset-3,.col-md-offset-4,.col-md-offset-5,.col-md-offset-6,.col-md-offset-7,.col-md-offset-8,.col-md-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-md{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-md-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-md-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-md-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-md-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-md-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-md-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-md-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-md-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-md-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-md-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-md-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-md-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-md-offset-0{margin-left:0}.col-md-offset-1{margin-left:8.33333333%}.col-md-offset-2{margin-left:16.66666667%}.col-md-offset-3{margin-left:25%}.col-md-offset-4{margin-left:33.33333333%}.col-md-offset-5{margin-left:41.66666667%}.col-md-offset-6{margin-left:50%}.col-md-offset-7{margin-left:58.33333333%}.col-md-offset-8{margin-left:66.66666667%}.col-md-offset-9{margin-left:75%}.col-md-offset-10{margin-left:83.33333333%}.col-md-offset-11{margin-left:91.66666667%}.start-md{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-md{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-md{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-md{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-md{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-md{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-md{-ms-flex-pack:distribute;justify-content:space-around}.between-md{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-md{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-md{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}@media only screen and (min-width:75em){.container{width:76rem}.col-lg,.col-lg-1,.col-lg-10,.col-lg-11,.col-lg-12,.col-lg-2,.col-lg-3,.col-lg-4,.col-lg-5,.col-lg-6,.col-lg-7,.col-lg-8,.col-lg-9,.col-lg-offset-0,.col-lg-offset-1,.col-lg-offset-10,.col-lg-offset-11,.col-lg-offset-12,.col-lg-offset-2,.col-lg-offset-3,.col-lg-offset-4,.col-lg-offset-5,.col-lg-offset-6,.col-lg-offset-7,.col-lg-offset-8,.col-lg-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-lg{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-lg-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-lg-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-lg-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-lg-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-lg-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-lg-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-lg-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-lg-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-lg-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-lg-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-lg-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-lg-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-lg-offset-0{margin-left:0}.col-lg-offset-1{margin-left:8.33333333%}.col-lg-offset-2{margin-left:16.66666667%}.col-lg-offset-3{margin-left:25%}.col-lg-offset-4{margin-left:33.33333333%}.col-lg-offset-5{margin-left:41.66666667%}.col-lg-offset-6{margin-left:50%}.col-lg-offset-7{margin-left:58.33333333%}.col-lg-offset-8{margin-left:66.66666667%}.col-lg-offset-9{margin-left:75%}.col-lg-offset-10{margin-left:83.33333333%}.col-lg-offset-11{margin-left:91.66666667%}.start-lg{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-lg{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-lg{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-lg{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-lg{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-lg{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-lg{-ms-flex-pack:distribute;justify-content:space-around}.between-lg{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-lg{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-lg{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}</style>
  

  
    <script>
    MathJax = {
        tex: {
            inlineMath: [["$", "$"], ["\\(", "\\)"]],
            displayMath: [["$$", "$$"]],
            processEscapes: true,
            processEnvironments: true,
            tags: "ams",
        },
        options: {
            skipHtmlTags: [
                "script",
                "noscript",
                "style",
                "textarea",
                "pre",
            ],
        },
        startup: {
            ready: () => {
                MathJax.startup.defaultReady();
                
                const all = MathJax.typesetPromise();
                all.then(() => {
                    document.querySelectorAll(".MathJax").forEach(
                        (el) => {
                            el.parentNode.className += " has-jax";
                        },
                    );
                });
            },
        },
    };
</script>
<script
    id="MathJax-script"
    async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js"
></script>

  

  

  <link href="/index.xml" rel="alternate" type="application/rss+xml"
    title="L1nker4&#39;s Blog | 格木观云">
  
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css?family=Bree+Serif|Bungee+Shade" rel="stylesheet">
  
  

  
  

  
<script async src="https://www.googletagmanager.com/gtag/js?id=G-DCQDH3T3WV"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-DCQDH3T3WV');
</script>

</head>


<body>
  <article class="post " id="article">
    <div class="row">
      <div class="col-xs-12">
        <div class="site-header">
          
<header>
  <div class="header-title">
    <a href="/"
      >L1nker4&#39;s Blog</a
    >
  </div>
  <div class="header-subtitle">提升认知，解构世界，行有不得，反求诸己</div>
</header>
<div class="row end-md header-items">
  
  <div class="header-item">
    <a href="/links" target="_blank">Links</a>
  </div>
  
  <div class="header-item">
    <a href="/about" target="_blank">About</a>
  </div>
  
  <div class="header-item">
    <a href="/index.xml" target="_blank">RSS</a>
  </div>
  
</div>
<div class="row">
   
</div>
<div class="header-line"></div>

        </div>
        <header class="post-header">
          <h1 class="post-title">Semantic Caching（语意缓存）：AI应用降本增效利器</h1>
          
          <div class="row post-desc">
            <div class="col-xs-6">
              
              <time class="post-date" datetime="2026-02-01 15:41:39 CST">
                
                  2026-02-01
                
              </time>
              
            </div>
            <div class="col-xs-6">
              
            </div>
          </div>
          
        </header>

        <div class="row">
          <div class="col-xs-12 col-md-9">
            <div class="post-content markdown-body">
              
              <h1 id="1-intro">1. Intro</h1>
<p>传统缓存的核心逻辑是<strong>精确字符串匹配</strong>：将查询作为 key完全一致时命中缓存。这种机制在静态内容分发、API 响应缓存等场景下运作良好，但在AI应用领域的表现较差，相似意图的Query无法精准命中。语义缓存（Semantic Caching）是一种利用Embedding向量化和向量相似度搜索来实现基于<strong>语义相似</strong>进行缓存匹配的机制。</p>
<p>语义缓存的工作流程可以概括为四个阶段：</p>
<pre tabindex="0"><code>
用户查询 → [1. Embedding 向量化] → [2. 向量相似度搜索] → Hit? → [3. 返回缓存结果]

                                    ↓ Miss

                                [4. 调用 LLM → 缓存结果]
</code></pre><ul>
<li><strong>Embedding 向量化</strong>：将用户的自然语言查询通过 Embedding 模型映射为高维向量。这一向量编码了查询的语义信息，使得含义相近的文本在向量空间中彼此接近。</li>
<li><strong>向量相似度搜索</strong> ：将新查询的向量与向量数据库中已存储的缓存向量进行比较，使用余弦距离（Cosine Distance）等度量方式计算语义距离，找出最近邻。</li>
<li><strong>缓存命中判定</strong> ：若最近邻的距离小于预设阈值（如 0.15），则判定为缓存命中，直接返回对应的 LLM 响应。</li>
<li><strong>缓存未命中处理</strong> 若无满足阈值条件的缓存结果，则将查询发送至 LLM 获取响应，并将该查询的 Embedding 向量与 LLM 响应一起写入缓存，供后续请求复用。</li>
</ul>
<p>语义缓存在客服聊天机器人、企业内部知识库等场景中能够发挥显著价值，此类场景大量Query集中在少数高频问题中，使用语意缓存可以显著降低AI应用的token成本。</p>
<hr>
<h1 id="2-基于redisvl实现语义缓存">2. 基于RedisVL实现语义缓存</h1>
<h2 id="21-redisvl介绍">2.1. RedisVL介绍</h2>
<p><strong>RedisVL（Redis Vector Library）</strong> 是 Redis 官方提供的 Python 客户端库，专为 AI 应用场景设计。它在 Redis 核心的高性能数据存储能力之上，封装了向量索引管理、多种 Embedding 模型集成、向量相似度搜索等功能，使开发者无需直接操作底层的 RediSearch 命令即可构建向量检索应用。在语义缓存领域，RedisVL 提供了 <code>SemanticCache</code> 类作为核心抽象，将索引创建、Embedding 向量化、KNN 搜索、阈值判定、TTL 管理等操作封装为简洁的 <code>check()</code> / <code>store()</code> API。同时，RedisVL 内置了对 OpenAI、HuggingFace、Cohere 等主流 Embedding Model的适配，并支持 Tag 和 Numeric 过滤实现多租户缓存隔离。</p>
<h2 id="22-缓存实例创建">2.2. 缓存实例创建</h2>
<p>RedisVL 将索引创建、向量化、向量序列化、KNN搜索等底层细节全部封装在内部。开发者只需指定缓存名称、Redis 连接地址、距离阈值和Embedding模型即可完成初始化。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> redisvl.extensions.cache.llm <span style="color:#f92672">import</span> SemanticCache
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> redisvl.utils.vectorize <span style="color:#f92672">import</span> OpenAITextVectorizer, HFTextVectorizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">create_cache</span>() <span style="color:#f92672">-&gt;</span> SemanticCache:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> EMBEDDING_TYPE <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;local&#34;</span>:
</span></span><span style="display:flex;"><span>        vectorizer <span style="color:#f92672">=</span> HFTextVectorizer(model<span style="color:#f92672">=</span>EMBEDDING_MODEL)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>        vectorizer <span style="color:#f92672">=</span> OpenAITextVectorizer(
</span></span><span style="display:flex;"><span>            model<span style="color:#f92672">=</span>EMBEDDING_MODEL,
</span></span><span style="display:flex;"><span>            api_config<span style="color:#f92672">=</span>{<span style="color:#e6db74">&#34;api_key&#34;</span>: OPENAI_API_KEY, <span style="color:#e6db74">&#34;base_url&#34;</span>: OPENAI_BASE_URL},
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>    cache <span style="color:#f92672">=</span> SemanticCache(
</span></span><span style="display:flex;"><span>        name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;llmcache&#34;</span>,
</span></span><span style="display:flex;"><span>        redis_url<span style="color:#f92672">=</span>REDIS_URL,
</span></span><span style="display:flex;"><span>        distance_threshold<span style="color:#f92672">=</span>DISTANCE_THRESHOLD,
</span></span><span style="display:flex;"><span>        vectorizer<span style="color:#f92672">=</span>vectorizer,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    cache<span style="color:#f92672">.</span>set_ttl(TTL_SECONDS)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> cache
</span></span></code></pre></div><h2 id="23-缓存查询与存储">2.3. 缓存查询与存储</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">answer_question</span>(openai_client, cache, question):
</span></span><span style="display:flex;"><span>    results <span style="color:#f92672">=</span> cache<span style="color:#f92672">.</span>check(prompt<span style="color:#f92672">=</span>question, return_fields<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#34;prompt&#34;</span>, <span style="color:#e6db74">&#34;response&#34;</span>])
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> results:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> results[<span style="color:#ae81ff">0</span>][<span style="color:#e6db74">&#34;response&#34;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 缓存未命中，调用 LLM 并存入缓存</span>
</span></span><span style="display:flex;"><span>    llm_response <span style="color:#f92672">=</span> ask_llm(openai_client, question)
</span></span><span style="display:flex;"><span>    cache<span style="color:#f92672">.</span>store(prompt<span style="color:#f92672">=</span>question, response<span style="color:#f92672">=</span>llm_response)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> llm_response
</span></span></code></pre></div><h1 id="3-总结">3. 总结</h1>
<p>语义缓存通过将 Embedding 向量化与向量相似度搜索引入缓存匹配流程，从根本上解决了传统缓存在自然语言场景下命中率低的问题。其技术架构由三个核心组件构成——Embedding 模型、向量数据库和缓存存储，在实际生产项目中需要选取合适的距离阈值和Embeddind模型。</p>

            </div>
          </div>
          <div class="col-xs-12 col-md-3">
            <div class="post-toc">
              <nav id="TableOfContents">
  <ul>
    <li><a href="#1-intro">1. Intro</a></li>
    <li><a href="#2-基于redisvl实现语义缓存">2. 基于RedisVL实现语义缓存</a>
      <ul>
        <li><a href="#21-redisvl介绍">2.1. RedisVL介绍</a></li>
        <li><a href="#22-缓存实例创建">2.2. 缓存实例创建</a></li>
        <li><a href="#23-缓存查询与存储">2.3. 缓存查询与存储</a></li>
      </ul>
    </li>
    <li><a href="#3-总结">3. 总结</a></li>
  </ul>
</nav>
            </div>
          </div>
        </div>

        <div class="row middle-xs">
          <div class="col-xs-12">
            
          </div>
        </div>
        
          <div class="row">
            <div class="col-xs-12">
              
            </div>
          </div>

          



          
          
          <div style="height: 50px;"></div>
          
          <div class="post-comments">
            <div id="disqus_thread"></div>
<script>
  window.addEventListener("load", () => {
    (function() {
      
      var d = document,
        s = d.createElement("script");
      s.src = "https://evl1nker4.disqus.com/embed.js";
      s.setAttribute("data-timestamp", +new Date());
      (d.head || d.body).appendChild(s);
    })();
  });
</script>
<noscript
  >Please enable JavaScript to view the
  <a href="https://disqus.com/?ref_noscript"
    >comments powered by Disqus.</a
  ></noscript
>

          </div>
          
        

        <div class="site-footer">
  
  
</div>

      </div>
    </div>
  </article>

  

<script>
  
  
    
    
  
</script>

  

</body>

</html>