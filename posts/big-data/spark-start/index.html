<!DOCTYPE html>
<html lang="en">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  <meta name="generator" content="Hugo 0.140.2">

  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="author" content="" />
  <meta property="og:url" content="http://localhost:1313/posts/big-data/spark-start/" />
  <link rel="canonical" href="http://localhost:1313/posts/big-data/spark-start/" /><link rel="apple-touch-icon" href="favicon.ico" />
  <link rel="icon" href="favicon.ico" />
  <link rel="shortcut" href="favicon.ico" /><link rel="alternate" type="application/atom+xml" href="http://localhost:1313/index.xml" title="l1nker4&#39;s Blog">

  <script type="application/ld+json">
  {
      "@context" : "http://schema.org",
      "@type" : "BlogPosting",
      "mainEntityOfPage": {
           "@type": "WebPage",
           "@id": "http:\/\/localhost:1313\/"
      },
      "articleSection" : "posts",
      "name" : "Spark入门",
      "headline" : "Spark入门",
      "description" : "简介 Apache Spark是一个分布式计算系统，具备以下特点：\n使用RDD(Resilient Distributed Datasets)，提供了比MapReduce更为丰富的模型 基于内存计算，性能比MapReduce模型高 集成离线计算、实时计算、机器学习、图计算等模块 核心模块：\nSpark Core：提供Spark核心功能，是SQL、Streaming等模块实现的基础。 Spark SQL：提供SQL进行数据查询的组件 Spark Streaming：提供流式计算的组件 MLlib：Spark平台的机器学习算法库 GraphX：面向图计算的组件 Spark名词解释：\n名称 含义 Application 指用户提交的 Spark 应用程序 Job 指 Spark 作业，是 Application 的子集，由行动算子（action）触发 Stage 指 Spark 阶段，是 Job 的子集，以 RDD 的宽依赖为界 Task 指 Spark 任务，是 Stage 的子集，Spark 中最基本的任务执行单元，对应单个线程，会被封装成 TaskDescription 对象提交到 Executor 的线程池中执行 Driver 运行用户程序main()方法并创建SparkContext的实例 Cluster Manager 集群管理器，例如Yarn、Mesos、Kubernetes等 Spark运行过程：\nDriver执行用户程序的main方法，并创建SparkContext，与Cluster Manager建立连接。 Cluster Manager为用户程序分配计算资源，返回可使用的Executor列表。 获取Executor资源后，Spark会将用户程序代码以及依赖包，发送给Executor SparkContext发送task到Executor，由executor执行计算任务。 Demo \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.spark\u0026lt;\/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spark-core_2.12\u0026lt;\/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.2\u0026lt;\/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;\/scope\u0026gt; \u0026lt;\/dependency\u0026gt; import org.apache.spark.SparkConf; import org.apache.spark.api.java.JavaPairRDD; import org.apache.spark.api.java.JavaRDD; import org.apache.spark.api.java.JavaSparkContext; import scala.Tuple2; import java.util.Arrays; public class WordCountDemo { private static void wordCount(String fileName) { SparkConf sparkConf = new SparkConf().setMaster(\u0026#34;local\u0026#34;).setAppName(\u0026#34;JD Word Counter\u0026#34;); JavaSparkContext sparkContext = new JavaSparkContext(sparkConf); JavaRDD\u0026lt;String\u0026gt; inputFile = sparkContext.textFile(fileName); JavaRDD\u0026lt;String\u0026gt; wordsFromFile = inputFile.flatMap(content -\u0026gt; Arrays.asList(content.split(\u0026#34; \u0026#34;)).iterator()); JavaPairRDD countData = wordsFromFile.mapToPair(t -\u0026gt; new Tuple2(t, 1)).reduceByKey((x, y) -\u0026gt; (int) x \u002b (int) y); countData.saveAsTextFile(\u0026#34;CountData\u0026#34;); } public static void main(String[] args) { if (args.length == 0) { System.out.println(\u0026#34;No files provided.\u0026#34;); System.exit(0); } wordCount(args[0]); } } 提交应用：\n",
      "inLanguage" : "en-US",
      "author" : "",
      "creator" : "",
      "publisher": "",
      "accountablePerson" : "",
      "copyrightHolder" : "",
      "copyrightYear" : "2024",
      "datePublished": "2024-11-12 15:37:52 \u002b0800 CST",
      "dateModified" : "2024-11-12 15:37:52 \u002b0800 CST",
      "url" : "http:\/\/localhost:1313\/posts\/big-data\/spark-start\/",
      "keywords" : [  ]
  }
</script>
<title>Spark入门</title>
  <meta property="og:title" content="Spark入门" />
  <meta property="og:type" content="article" />
  <meta property="og:description" content="简介 Apache Spark是一个分布式计算系统，具备以下特点：
使用RDD(Resilient Distributed Datasets)，提供了比MapReduce更为丰富的模型 基于内存计算，性能比MapReduce模型高 集成离线计算、实时计算、机器学习、图计算等模块 核心模块：
Spark Core：提供Spark核心功能，是SQL、Streaming等模块实现的基础。 Spark SQL：提供SQL进行数据查询的组件 Spark Streaming：提供流式计算的组件 MLlib：Spark平台的机器学习算法库 GraphX：面向图计算的组件 Spark名词解释：
名称 含义 Application 指用户提交的 Spark 应用程序 Job 指 Spark 作业，是 Application 的子集，由行动算子（action）触发 Stage 指 Spark 阶段，是 Job 的子集，以 RDD 的宽依赖为界 Task 指 Spark 任务，是 Stage 的子集，Spark 中最基本的任务执行单元，对应单个线程，会被封装成 TaskDescription 对象提交到 Executor 的线程池中执行 Driver 运行用户程序main()方法并创建SparkContext的实例 Cluster Manager 集群管理器，例如Yarn、Mesos、Kubernetes等 Spark运行过程：
Driver执行用户程序的main方法，并创建SparkContext，与Cluster Manager建立连接。 Cluster Manager为用户程序分配计算资源，返回可使用的Executor列表。 获取Executor资源后，Spark会将用户程序代码以及依赖包，发送给Executor SparkContext发送task到Executor，由executor执行计算任务。 Demo &lt;dependency&gt; &lt;groupId&gt;org.apache.spark&lt;/groupId&gt; &lt;artifactId&gt;spark-core_2.12&lt;/artifactId&gt; &lt;version&gt;3.1.2&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; import org.apache.spark.SparkConf; import org.apache.spark.api.java.JavaPairRDD; import org.apache.spark.api.java.JavaRDD; import org.apache.spark.api.java.JavaSparkContext; import scala.Tuple2; import java.util.Arrays; public class WordCountDemo { private static void wordCount(String fileName) { SparkConf sparkConf = new SparkConf().setMaster(&#34;local&#34;).setAppName(&#34;JD Word Counter&#34;); JavaSparkContext sparkContext = new JavaSparkContext(sparkConf); JavaRDD&lt;String&gt; inputFile = sparkContext.textFile(fileName); JavaRDD&lt;String&gt; wordsFromFile = inputFile.flatMap(content -&gt; Arrays.asList(content.split(&#34; &#34;)).iterator()); JavaPairRDD countData = wordsFromFile.mapToPair(t -&gt; new Tuple2(t, 1)).reduceByKey((x, y) -&gt; (int) x &#43; (int) y); countData.saveAsTextFile(&#34;CountData&#34;); } public static void main(String[] args) { if (args.length == 0) { System.out.println(&#34;No files provided.&#34;); System.exit(0); } wordCount(args[0]); } } 提交应用：
" />
  <meta name="description" content="简介 Apache Spark是一个分布式计算系统，具备以下特点：
使用RDD(Resilient Distributed Datasets)，提供了比MapReduce更为丰富的模型 基于内存计算，性能比MapReduce模型高 集成离线计算、实时计算、机器学习、图计算等模块 核心模块：
Spark Core：提供Spark核心功能，是SQL、Streaming等模块实现的基础。 Spark SQL：提供SQL进行数据查询的组件 Spark Streaming：提供流式计算的组件 MLlib：Spark平台的机器学习算法库 GraphX：面向图计算的组件 Spark名词解释：
名称 含义 Application 指用户提交的 Spark 应用程序 Job 指 Spark 作业，是 Application 的子集，由行动算子（action）触发 Stage 指 Spark 阶段，是 Job 的子集，以 RDD 的宽依赖为界 Task 指 Spark 任务，是 Stage 的子集，Spark 中最基本的任务执行单元，对应单个线程，会被封装成 TaskDescription 对象提交到 Executor 的线程池中执行 Driver 运行用户程序main()方法并创建SparkContext的实例 Cluster Manager 集群管理器，例如Yarn、Mesos、Kubernetes等 Spark运行过程：
Driver执行用户程序的main方法，并创建SparkContext，与Cluster Manager建立连接。 Cluster Manager为用户程序分配计算资源，返回可使用的Executor列表。 获取Executor资源后，Spark会将用户程序代码以及依赖包，发送给Executor SparkContext发送task到Executor，由executor执行计算任务。 Demo &lt;dependency&gt; &lt;groupId&gt;org.apache.spark&lt;/groupId&gt; &lt;artifactId&gt;spark-core_2.12&lt;/artifactId&gt; &lt;version&gt;3.1.2&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; import org.apache.spark.SparkConf; import org.apache.spark.api.java.JavaPairRDD; import org.apache.spark.api.java.JavaRDD; import org.apache.spark.api.java.JavaSparkContext; import scala.Tuple2; import java.util.Arrays; public class WordCountDemo { private static void wordCount(String fileName) { SparkConf sparkConf = new SparkConf().setMaster(&#34;local&#34;).setAppName(&#34;JD Word Counter&#34;); JavaSparkContext sparkContext = new JavaSparkContext(sparkConf); JavaRDD&lt;String&gt; inputFile = sparkContext.textFile(fileName); JavaRDD&lt;String&gt; wordsFromFile = inputFile.flatMap(content -&gt; Arrays.asList(content.split(&#34; &#34;)).iterator()); JavaPairRDD countData = wordsFromFile.mapToPair(t -&gt; new Tuple2(t, 1)).reduceByKey((x, y) -&gt; (int) x &#43; (int) y); countData.saveAsTextFile(&#34;CountData&#34;); } public static void main(String[] args) { if (args.length == 0) { System.out.println(&#34;No files provided.&#34;); System.exit(0); } wordCount(args[0]); } } 提交应用：
" />
  <meta property="og:locale" content="en-us" /><meta property="og:image" content="favicon.ico" />
  

  
    <style>body{font-family:bree serif,sans-serif;-webkit-font-smoothing:antialiased;margin:0 20px}article{max-width:800px;margin-left:auto;margin-right:auto}a{color:#000;text-decoration:none}a:hover{font-weight:600;text-decoration:underline}.post-ads{margin:50px 0}.markdown-body{font-size:18px;max-width:100%}.markdown-body a{text-decoration:underline;text-decoration-color:#000}.markdown-body blockquote{margin:0;padding:0 1em;color:#57606a;border-left:.25em solid #d0d7de}.markdown-body pre{padding:16px;overflow:auto;border-radius:10px}.markdown-body code{padding:.2em .4em;font-size:85%;background-color:#f6f8fa;border-radius:6px}.markdown-body pre>code{padding:0;font-size:85%;background-color:inherit;border:0;font-family:SFMono-Regular,Consolas,Liberation Mono,Menlo,monospace}.Chinese .markdown-body{line-height:200%}.site-date-catalog{font-size:2rem}.header-title{font-size:2rem;font-weight:700;margin-top:32px;font-family:bungee shade,sans-serif}.header-title a{text-decoration:none}.header-subtitle{color:#666}.header-items{margin:10px 0}.header-item{margin:0 5px}.header-line{width:100%;border-width:2px;border-color:#482936;border-style:solid none none none}.lang-switch{font-weight:600}#posts-list{min-height:600px}.posts-line{font-size:1.2rem;margin:12px 0}.posts-categories{font-size:.8rem;margin:auto;text-align:center}.posts-category{padding:3px 0;border:#000 2px solid;border-radius:5px}.site-footer{margin-top:50px}.site-footer-item{margin-right:12px}.post-header{margin-bottom:50px}.post-title{font-size:2rem;font-weight:600}.post-tags{display:inline;font-weight:600;padding:2px 5px;margin-right:6px;border:#000 2px solid;border-radius:5px}.post-date{font-weight:800;font-style:italic}.post-author{float:right;font-weight:600}.page-content{min-height:60%}.post-content{margin-bottom:50px}.post-content p{hyphens:auto;line-height:1.8;text-justify:ideographic;margin-bottom:1em}.post-content img{max-width:100%;display:block;margin-right:auto;margin-top:6px}.post-content .post-gallery{display:flex;flex-wrap:wrap;gap:6px}.post-content .post-gallery img{margin-right:auto;margin-top:auto;width:calc(50% - 3px)}.related-content{border-width:3px;border-style:solid;border-color:#000;padding:0 10px;margin-bottom:50px;margin-top:100px}.related-content li{margin:5px 0}.taxonomy-term{font-size:3rem}.gallery-img{text-align:center}.gallery-img span{text-align:center}.gallery-img-desc{font-size:.8em;font-weight:800}#disqus_thread{position:relative}#disqus_thread:after{content:"";display:block;height:55px;width:100%;position:absolute;bottom:0;background:#fff}@media screen and (max-width:600px){.header-title,.header-subtitle,.header-items{}.posts-line{font-size:16px}.markdown-body{font-size:16px}.post-title{font-size:2rem}.post-content p{letter-spacing:.05em}.post-content .post-gallery img{width:100%}}@media screen and (max-width:48em){.posts-category{display:none}}table,th,td{border-collapse:collapse;border-style:solid}</style>
  
  
    <style>.container,.container-fluid{margin-right:auto;margin-left:auto}.container-fluid{padding-right:2rem;padding-left:2rem}.row{box-sizing:border-box;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:0;-ms-flex:0 1 auto;flex:initial;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-ms-flex-wrap:wrap;flex-wrap:wrap;margin-right:-.5rem;margin-left:-.5rem}.row.reverse{-webkit-box-orient:horizontal;-webkit-box-direction:reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse}.col.reverse{-webkit-box-orient:vertical;-webkit-box-direction:reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse}.col-xs,.col-xs-1,.col-xs-10,.col-xs-11,.col-xs-12,.col-xs-2,.col-xs-3,.col-xs-4,.col-xs-5,.col-xs-6,.col-xs-7,.col-xs-8,.col-xs-9,.col-xs-offset-0,.col-xs-offset-1,.col-xs-offset-10,.col-xs-offset-11,.col-xs-offset-12,.col-xs-offset-2,.col-xs-offset-3,.col-xs-offset-4,.col-xs-offset-5,.col-xs-offset-6,.col-xs-offset-7,.col-xs-offset-8,.col-xs-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-xs{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-xs-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-xs-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-xs-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-xs-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-xs-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-xs-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-xs-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-xs-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-xs-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-xs-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-xs-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-xs-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-xs-offset-0{margin-left:0}.col-xs-offset-1{margin-left:8.33333333%}.col-xs-offset-2{margin-left:16.66666667%}.col-xs-offset-3{margin-left:25%}.col-xs-offset-4{margin-left:33.33333333%}.col-xs-offset-5{margin-left:41.66666667%}.col-xs-offset-6{margin-left:50%}.col-xs-offset-7{margin-left:58.33333333%}.col-xs-offset-8{margin-left:66.66666667%}.col-xs-offset-9{margin-left:75%}.col-xs-offset-10{margin-left:83.33333333%}.col-xs-offset-11{margin-left:91.66666667%}.start-xs{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-xs{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-xs{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-xs{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-xs{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-xs{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-xs{-ms-flex-pack:distribute;justify-content:space-around}.between-xs{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-xs{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-xs{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}@media only screen and (min-width:48em){.container{width:49rem}.col-sm,.col-sm-1,.col-sm-10,.col-sm-11,.col-sm-12,.col-sm-2,.col-sm-3,.col-sm-4,.col-sm-5,.col-sm-6,.col-sm-7,.col-sm-8,.col-sm-9,.col-sm-offset-0,.col-sm-offset-1,.col-sm-offset-10,.col-sm-offset-11,.col-sm-offset-12,.col-sm-offset-2,.col-sm-offset-3,.col-sm-offset-4,.col-sm-offset-5,.col-sm-offset-6,.col-sm-offset-7,.col-sm-offset-8,.col-sm-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-sm{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-sm-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-sm-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-sm-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-sm-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-sm-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-sm-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-sm-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-sm-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-sm-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-sm-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-sm-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-sm-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-sm-offset-0{margin-left:0}.col-sm-offset-1{margin-left:8.33333333%}.col-sm-offset-2{margin-left:16.66666667%}.col-sm-offset-3{margin-left:25%}.col-sm-offset-4{margin-left:33.33333333%}.col-sm-offset-5{margin-left:41.66666667%}.col-sm-offset-6{margin-left:50%}.col-sm-offset-7{margin-left:58.33333333%}.col-sm-offset-8{margin-left:66.66666667%}.col-sm-offset-9{margin-left:75%}.col-sm-offset-10{margin-left:83.33333333%}.col-sm-offset-11{margin-left:91.66666667%}.start-sm{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-sm{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-sm{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-sm{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-sm{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-sm{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-sm{-ms-flex-pack:distribute;justify-content:space-around}.between-sm{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-sm{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-sm{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}@media only screen and (min-width:64em){.container{width:65rem}.col-md,.col-md-1,.col-md-10,.col-md-11,.col-md-12,.col-md-2,.col-md-3,.col-md-4,.col-md-5,.col-md-6,.col-md-7,.col-md-8,.col-md-9,.col-md-offset-0,.col-md-offset-1,.col-md-offset-10,.col-md-offset-11,.col-md-offset-12,.col-md-offset-2,.col-md-offset-3,.col-md-offset-4,.col-md-offset-5,.col-md-offset-6,.col-md-offset-7,.col-md-offset-8,.col-md-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-md{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-md-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-md-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-md-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-md-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-md-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-md-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-md-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-md-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-md-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-md-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-md-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-md-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-md-offset-0{margin-left:0}.col-md-offset-1{margin-left:8.33333333%}.col-md-offset-2{margin-left:16.66666667%}.col-md-offset-3{margin-left:25%}.col-md-offset-4{margin-left:33.33333333%}.col-md-offset-5{margin-left:41.66666667%}.col-md-offset-6{margin-left:50%}.col-md-offset-7{margin-left:58.33333333%}.col-md-offset-8{margin-left:66.66666667%}.col-md-offset-9{margin-left:75%}.col-md-offset-10{margin-left:83.33333333%}.col-md-offset-11{margin-left:91.66666667%}.start-md{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-md{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-md{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-md{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-md{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-md{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-md{-ms-flex-pack:distribute;justify-content:space-around}.between-md{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-md{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-md{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}@media only screen and (min-width:75em){.container{width:76rem}.col-lg,.col-lg-1,.col-lg-10,.col-lg-11,.col-lg-12,.col-lg-2,.col-lg-3,.col-lg-4,.col-lg-5,.col-lg-6,.col-lg-7,.col-lg-8,.col-lg-9,.col-lg-offset-0,.col-lg-offset-1,.col-lg-offset-10,.col-lg-offset-11,.col-lg-offset-12,.col-lg-offset-2,.col-lg-offset-3,.col-lg-offset-4,.col-lg-offset-5,.col-lg-offset-6,.col-lg-offset-7,.col-lg-offset-8,.col-lg-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-lg{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-lg-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-lg-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-lg-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-lg-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-lg-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-lg-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-lg-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-lg-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-lg-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-lg-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-lg-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-lg-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-lg-offset-0{margin-left:0}.col-lg-offset-1{margin-left:8.33333333%}.col-lg-offset-2{margin-left:16.66666667%}.col-lg-offset-3{margin-left:25%}.col-lg-offset-4{margin-left:33.33333333%}.col-lg-offset-5{margin-left:41.66666667%}.col-lg-offset-6{margin-left:50%}.col-lg-offset-7{margin-left:58.33333333%}.col-lg-offset-8{margin-left:66.66666667%}.col-lg-offset-9{margin-left:75%}.col-lg-offset-10{margin-left:83.33333333%}.col-lg-offset-11{margin-left:91.66666667%}.start-lg{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-lg{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-lg{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-lg{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-lg{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-lg{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-lg{-ms-flex-pack:distribute;justify-content:space-around}.between-lg{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-lg{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-lg{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}</style>
  

  

  <link href="/index.xml" rel="alternate" type="application/rss+xml"
    title="l1nker4&#39;s Blog">
  
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css?family=Bree+Serif|Bungee+Shade" rel="stylesheet">
  
  

  
  <script src="js/baidu.js"></script>
</head>


<body>
  <article class="post " id="article">
    <div class="row">
      <div class="col-xs-12">
        <div class="site-header">
          
<header>
  <div class="header-title">
    <a href="/"
      >L1nker4</a
    >
  </div>
  <div class="header-subtitle"></div>
</header>
<div class="row end-md header-items">
  
  <div class="header-item">
    <a href="/links" target="_blank">Links</a>
  </div>
  
  <div class="header-item">
    <a href="/about" target="_blank">About</a>
  </div>
  
</div>
<div class="row">
   
</div>
<div class="header-line"></div>

        </div>
        <header class="post-header">
          <h1 class="post-title">Spark入门</h1>
          
          <div class="row post-desc">
            <div class="col-xs-6">
              
              <time class="post-date" datetime="2024-11-12 15:37:52 CST">
                12 Nov 2024
              </time>
              
            </div>
            <div class="col-xs-6">
              
            </div>
          </div>
          
        </header>

        <div class="post-content markdown-body">
          
          <h2 id="简介">简介</h2>
<p>Apache Spark是一个分布式计算系统，具备以下特点：</p>
<ul>
<li>使用RDD(Resilient Distributed Datasets)，提供了比MapReduce更为丰富的模型</li>
<li>基于内存计算，性能比MapReduce模型高</li>
<li>集成离线计算、实时计算、机器学习、图计算等模块</li>
</ul>
<p>核心模块：</p>
<ul>
<li>Spark Core：提供Spark核心功能，是SQL、Streaming等模块实现的基础。</li>
<li>Spark SQL：提供SQL进行数据查询的组件</li>
<li>Spark Streaming：提供流式计算的组件</li>
<li>MLlib：Spark平台的机器学习算法库</li>
<li>GraphX：面向图计算的组件</li>
</ul>
<p>Spark名词解释：</p>
<table>
  <thead>
      <tr>
          <th><strong>名称</strong></th>
          <th><strong>含义</strong></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Application</td>
          <td>指用户提交的 Spark 应用程序</td>
      </tr>
      <tr>
          <td>Job</td>
          <td>指 Spark 作业，是 Application 的子集，由行动算子（action）触发</td>
      </tr>
      <tr>
          <td>Stage</td>
          <td>指 Spark 阶段，是 Job 的子集，以 RDD 的宽依赖为界</td>
      </tr>
      <tr>
          <td>Task</td>
          <td>指 Spark 任务，是 Stage 的子集，Spark 中最基本的任务执行单元，对应单个线程，会被封装成 TaskDescription 对象提交到 Executor 的线程池中执行</td>
      </tr>
      <tr>
          <td>Driver</td>
          <td>运行用户程序<code>main()</code>方法并创建SparkContext的实例</td>
      </tr>
      <tr>
          <td>Cluster Manager</td>
          <td>集群管理器，例如Yarn、Mesos、Kubernetes等</td>
      </tr>
      <tr>
          <td><img src="https://blog-1251613845.cos.ap-shanghai.myqcloud.com/20240729135117.png" alt="image.png"></td>
          <td></td>
      </tr>
  </tbody>
</table>
<p>Spark运行过程：</p>
<ol>
<li>Driver执行用户程序的main方法，并创建SparkContext，与Cluster Manager建立连接。</li>
<li>Cluster Manager为用户程序分配计算资源，返回可使用的Executor列表。</li>
<li>获取Executor资源后，Spark会将用户程序代码以及依赖包，发送给Executor</li>
<li>SparkContext发送task到Executor，由executor执行计算任务。</li>
</ol>
<h3 id="demo">Demo</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span><span style="color:#f92672">&lt;dependency&gt;</span>  
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&lt;groupId&gt;</span>org.apache.spark<span style="color:#f92672">&lt;/groupId&gt;</span>  
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&lt;artifactId&gt;</span>spark-core_2.12<span style="color:#f92672">&lt;/artifactId&gt;</span>  
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&lt;version&gt;</span>3.1.2<span style="color:#f92672">&lt;/version&gt;</span>  
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&lt;scope&gt;</span>provided<span style="color:#f92672">&lt;/scope&gt;</span>  
</span></span><span style="display:flex;"><span><span style="color:#f92672">&lt;/dependency&gt;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-java" data-lang="java"><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.spark.SparkConf;  
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.spark.api.java.JavaPairRDD;  
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.spark.api.java.JavaRDD;  
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.spark.api.java.JavaSparkContext;  
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> scala.Tuple2;  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> java.util.Arrays;  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span> <span style="color:#66d9ef">class</span> <span style="color:#a6e22e">WordCountDemo</span> {  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">private</span> <span style="color:#66d9ef">static</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">wordCount</span>(String fileName) {  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>        SparkConf sparkConf <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> SparkConf().<span style="color:#a6e22e">setMaster</span>(<span style="color:#e6db74">&#34;local&#34;</span>).<span style="color:#a6e22e">setAppName</span>(<span style="color:#e6db74">&#34;JD Word Counter&#34;</span>);  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>        JavaSparkContext sparkContext <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> JavaSparkContext(sparkConf);  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>        JavaRDD<span style="color:#f92672">&lt;</span>String<span style="color:#f92672">&gt;</span> inputFile <span style="color:#f92672">=</span> sparkContext.<span style="color:#a6e22e">textFile</span>(fileName);  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>        JavaRDD<span style="color:#f92672">&lt;</span>String<span style="color:#f92672">&gt;</span> wordsFromFile <span style="color:#f92672">=</span> inputFile.<span style="color:#a6e22e">flatMap</span>(content <span style="color:#f92672">-&gt;</span> Arrays.<span style="color:#a6e22e">asList</span>(content.<span style="color:#a6e22e">split</span>(<span style="color:#e6db74">&#34; &#34;</span>)).<span style="color:#a6e22e">iterator</span>());  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>        JavaPairRDD countData <span style="color:#f92672">=</span> wordsFromFile.<span style="color:#a6e22e">mapToPair</span>(t <span style="color:#f92672">-&gt;</span> <span style="color:#66d9ef">new</span> Tuple2(t, 1)).<span style="color:#a6e22e">reduceByKey</span>((x, y) <span style="color:#f92672">-&gt;</span> (<span style="color:#66d9ef">int</span>) x <span style="color:#f92672">+</span> (<span style="color:#66d9ef">int</span>) y);  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>        countData.<span style="color:#a6e22e">saveAsTextFile</span>(<span style="color:#e6db74">&#34;CountData&#34;</span>);  
</span></span><span style="display:flex;"><span>    }  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">public</span> <span style="color:#66d9ef">static</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">main</span>(String<span style="color:#f92672">[]</span> args) {  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> (args.<span style="color:#a6e22e">length</span> <span style="color:#f92672">==</span> 0) {  
</span></span><span style="display:flex;"><span>            System.<span style="color:#a6e22e">out</span>.<span style="color:#a6e22e">println</span>(<span style="color:#e6db74">&#34;No files provided.&#34;</span>);  
</span></span><span style="display:flex;"><span>            System.<span style="color:#a6e22e">exit</span>(0);  
</span></span><span style="display:flex;"><span>        }  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>        wordCount(args<span style="color:#f92672">[</span>0<span style="color:#f92672">]</span>);  
</span></span><span style="display:flex;"><span>    }  
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>提交应用：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>bin/spark-submit <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--class com.github.l1nker4.spark.WordCountDemo <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--master local <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>spark-demo-1.0-SNAPSHOT.jar data/word.txt
</span></span></code></pre></div><p>也可以通过spark-shell的方式，提交应用：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#75715e"># 需要配置JAVA_HOME</span>
</span></span><span style="display:flex;"><span>bin/spark-shell
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># data/word.txt提前创建</span>
</span></span><span style="display:flex;"><span>scala&gt; sc.textFile<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;data/word.txt&#34;</span><span style="color:#f92672">)</span>.flatMap<span style="color:#f92672">(</span>_.split<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;\n&#34;</span><span style="color:#f92672">))</span>.map<span style="color:#f92672">((</span>_,1<span style="color:#f92672">))</span>.reduceByKey<span style="color:#f92672">(</span>_+_<span style="color:#f92672">)</span>.collect
</span></span><span style="display:flex;"><span>res6: Array<span style="color:#f92672">[(</span>String, Int<span style="color:#f92672">)]</span> <span style="color:#f92672">=</span> Array<span style="color:#f92672">((</span>zhangsan,2<span style="color:#f92672">)</span>, <span style="color:#f92672">(</span>wangwu,1<span style="color:#f92672">)</span>, <span style="color:#f92672">(</span>lisi,1<span style="color:#f92672">))</span>
</span></span></code></pre></div><h2 id="部署方式">部署方式</h2>
<ul>
<li>local模式：单机多线程模拟Spark分布式计算，通常用于开发调试。</li>
<li>Standalone模式：以master-slave模式部署Spark集群。
<ul>
<li>master参数指定为master节点地址，例如：<code>spark://master:7077</code></li>
</ul>
</li>
<li>YARN模式：集群计算资源调度由YARN管理，无需部署启动Spark集群。
<ul>
<li>master参数指定为yarn</li>
</ul>
</li>
</ul>
<h3 id="local模式">local模式</h3>
<p>Web UI：http://localhost:4040/jobs/</p>
<p>提交应用：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>bin/spark-submit <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--class org.apache.spark.examples.SparkPi <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--master local<span style="color:#f92672">[</span>2<span style="color:#f92672">]</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>./examples/jars/spark-examples_2.12-3.1.2.jar <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span><span style="color:#ae81ff">10</span> <span style="color:#75715e"># 入口参数</span>
</span></span></code></pre></div><p>参数说明：</p>
<ul>
<li>本地模式下，master取值如下：
<ul>
<li><code>local</code>：只启动一个Executor</li>
<li><code>local[N]</code>：启动N个Executor</li>
<li><code>local[*]</code>：启动CPU核数相同的Executor</li>
</ul>
</li>
</ul>
<h2 id="rdd">RDD</h2>
<p>RDD(Resilient Distributed Datasets)代表一个不可变、可分区、支持并行计算的数据集合。</p>
<blockquote>
<p>《Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing》</p>
</blockquote>
<p>RDD特性：</p>
<ul>
<li>弹性
<ul>
<li>存储：内存不足时可以和磁盘进行数据交换</li>
<li>计算：计算出错时支持重试</li>
<li>容错：数据丢失可以自动恢复</li>
<li>分片：支持重新分片</li>
</ul>
</li>
<li>不可变：RDD只读，只能通过transformer生成新的RDD</li>
<li>支持并行计算：不同分区可以调度到不同节点上进行计算。</li>
</ul>
<p>五个核心方法：</p>
<table>
  <thead>
      <tr>
          <th><strong>名称</strong></th>
          <th><strong>含义</strong></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>getPartitions</td>
          <td>由子类实现，返回一个分区列表，用于执行并行计算</td>
      </tr>
      <tr>
          <td>compute</td>
          <td>由子类实现，是一个用于 <strong>计算每一个分区</strong> 的 <strong>函数</strong></td>
      </tr>
      <tr>
          <td>getDependencies</td>
          <td>由子类实现，获取当前 RDD 的依赖关系</td>
      </tr>
      <tr>
          <td>partitioner</td>
          <td>由子类实现（可选），可设置分区器对数据集进行分区（仅适用于 KV 类型的 RDD）</td>
      </tr>
      <tr>
          <td>getPreferredLocations</td>
          <td>由子类实现（可选），可在分区计算时指定 <strong>优先起始位置</strong>，有助于“移动计算”的实现</td>
      </tr>
  </tbody>
</table>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-scala" data-lang="scala"><span style="display:flex;"><span><span style="color:#66d9ef">#</span> 创建RDD
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">val</span> array<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">Array</span><span style="color:#f92672">[</span><span style="color:#66d9ef">Int</span><span style="color:#f92672">]</span> <span style="color:#66d9ef">=</span> <span style="color:#a6e22e">Array</span><span style="color:#f92672">(</span><span style="color:#ae81ff">1</span><span style="color:#f92672">,</span> <span style="color:#ae81ff">2</span><span style="color:#f92672">,</span> <span style="color:#ae81ff">3</span><span style="color:#f92672">,</span> <span style="color:#ae81ff">4</span><span style="color:#f92672">,</span> <span style="color:#ae81ff">5</span><span style="color:#f92672">)</span>  
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">val</span> rdd<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">RDD</span><span style="color:#f92672">[</span><span style="color:#66d9ef">Int</span><span style="color:#f92672">]</span> <span style="color:#66d9ef">=</span> sc<span style="color:#f92672">.</span>parallelize<span style="color:#f92672">(</span>array<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">#</span> 文件读取
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">val</span> lines<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">RDD</span><span style="color:#f92672">[</span><span style="color:#66d9ef">String</span><span style="color:#f92672">]</span> <span style="color:#66d9ef">=</span> sc<span style="color:#f92672">.</span>textFile<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;data/my.txt&#34;</span><span style="color:#f92672">)</span>
</span></span></code></pre></div><h3 id="rdd-partition">RDD Partition</h3>
<p>RDD Partition是数据源的部分片段，由InputFormat实现类按一定规则切分数据集之后的结果</p>
<h3 id="rdd算子">RDD算子</h3>
<h4 id="转换算子transformations">转换算子(transformations)</h4>
<p>转换算子会基于已有的RDD，按照一定规则创建新的RDD，仅记录RDD转换逻辑，不会触发计算。</p>
<table>
  <thead>
      <tr>
          <th><strong>操作</strong></th>
          <th><strong>含义</strong></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>filter</strong>(<em>func</em>)</td>
          <td>筛选出满足条件的元素，并返回一个新的数据集</td>
      </tr>
      <tr>
          <td><strong>map</strong>(<em>func</em>)</td>
          <td>将每个元素传递到函数 <em>func</em> 中，返回一个新的数据集，每个输入元素会映射到 <strong>1 个输出结果</strong></td>
      </tr>
      <tr>
          <td><strong>flatMap</strong>(<em>func</em>)</td>
          <td>与 map 相似，但每个输入元素都可以映射到 <strong>0 或多个输出结果</strong></td>
      </tr>
      <tr>
          <td><strong>mapPartitions</strong>(<em>func</em>)</td>
          <td>与 map 相似，但是传递给函数 <em>func</em> 的是每个分区数据集对应的迭代器</td>
      </tr>
      <tr>
          <td><strong>distinct</strong>(<em>func</em>)</td>
          <td>对原数据集进行去重，并返回新的数据集</td>
      </tr>
      <tr>
          <td><strong>groupByKey</strong>(<em>[numPartitions]</em>)</td>
          <td>应用于 (K, V) 形式的数据集，返回一个新的 (K, Iterable<!-- raw HTML omitted -->) 形式的数据集，可通过 <em>numPartitions</em> 指定新数据集的分区数</td>
      </tr>
      <tr>
          <td><strong>reduceByKey</strong>(<em>func</em>, <em>[numPartitions]</em>)</td>
          <td>应用于 (K, V) 形式的数据集，返回一个新的 (K, V) 形式的数据集，新数据集中的 V 是原有数据集中每个 K 对应的 V 传递到 <em>func</em> 中进行聚合后的结果</td>
      </tr>
      <tr>
          <td><strong>aggregateByKey</strong>(<em>zeroValue</em>)(<em>seqOp</em>, <em>combOp</em>, <em>[numPartitions]</em>)</td>
          <td>应用于 (K, V) 形式的数据集，返回一个新的 (K, U) 形式的数据集，新数据集中的 U 是原有数据集中每个 K 对应的 V 传递到 <em>seqOp</em> 与 <em>combOp</em> 的联合函数且与 <em>zeroValue</em> 聚合后的结果</td>
      </tr>
      <tr>
          <td><strong>sortByKey</strong>(<em>[ascending]</em>, <em>[numPartitions]</em>)</td>
          <td>应用于 (K, V) 形式的数据集，返回一个根据 K 排序的数据集，K 按升序或降序排序由 <em>ascending</em> 指定</td>
      </tr>
      <tr>
          <td><strong>union</strong>(<em>func</em>)</td>
          <td>将两个数据集中的元素合并到一个新的数据集</td>
      </tr>
      <tr>
          <td><strong>join</strong>(<em>func</em>)</td>
          <td>表示内连接，对于给定的两个形式分别为 (K, V) 和 (K, W) 的数据集，只有在两个数据集中都存在的 K 才会被输出，最终得到一个 (K, (V, W)) 类型的数据集</td>
      </tr>
      <tr>
          <td><strong>repartition</strong>(<em>numPartitions</em>)</td>
          <td>对数据集进行重分区，新的分区数由 <em>numPartitions</em> 指定，包含shuffle操作，扩大/缩小分区都可用，性能较coaleace差</td>
      </tr>
      <tr>
          <td><strong>coaleace</strong>(<em>numPartitions</em>)</td>
          <td>对数据集进行重分区，新的分区数由 <em>numPartitions</em> 指定，不包含shuffle操作，缩小分区可用coaleace</td>
      </tr>
  </tbody>
</table>
<h4 id="行动算子actions">行动算子(actions)</h4>
<p>不会返回新的RDD，但是<strong>会触发任务执行</strong>，算子执行后，会向Spark发起job，Spark按照前置转换算子生成DAG并执行。</p>
<table>
  <thead>
      <tr>
          <th><strong>操作</strong></th>
          <th><strong>含义</strong></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>count</strong>()</td>
          <td>返回数据集中的元素个数</td>
      </tr>
      <tr>
          <td><strong>countByKey</strong>()</td>
          <td>仅适用于 (K, V) 形式的数据集，以 (K, Int) 形式的 Map 返回每个 K 的元素个数</td>
      </tr>
      <tr>
          <td><strong>collect</strong>()</td>
          <td>以数组的形式返回数据集中的所有元素</td>
      </tr>
      <tr>
          <td><strong>first</strong>()</td>
          <td>返回数据集中的第一个元素</td>
      </tr>
      <tr>
          <td><strong>take</strong>(<em>n</em>)</td>
          <td>以数组的形式返回数据集中的前 <em>n</em> 个元素</td>
      </tr>
      <tr>
          <td><strong>reduce</strong>(<em>func</em>)</td>
          <td>通过函数 <em>func</em>（输入两个参数并返回一个值）聚合数据集中的元素</td>
      </tr>
      <tr>
          <td><strong>foreach</strong>(<em>func</em>)</td>
          <td>将数据集中的每个元素传递到函数 <em>func</em> 中运行</td>
      </tr>
      <tr>
          <td><strong>saveAsTextFile</strong>(<em>path</em>)</td>
          <td>将数据集以文本格式写到本地磁盘或 HDFS 的指定目录下</td>
      </tr>
      <tr>
          <td><strong>saveAsSequenceFile</strong>(<em>path</em>)</td>
          <td>将数据集以 SequenceFile 格式写到本地磁盘或 HDFS 的指定目录下，仅适用于 (K, V) 形式且 K 和 V 均实现了 Hadoop Writable 接口的数据集</td>
      </tr>
      <tr>
          <td><strong>saveAsObjectFile</strong>(<em>path</em>)</td>
          <td>将数据集序列化成对象保存至本地磁盘或 HDFS 的指定目录下</td>
      </tr>
  </tbody>
</table>
<h3 id="rdd依赖关系">RDD依赖关系</h3>
<p>转换算子生成的新RDD，与原始RDD存在依赖关系，代码层面使用<strong>Dependency</strong>关联。</p>
<p>依赖类型：</p>
<ul>
<li>宽依赖：父RDD每个分区对应子RDD的多个分区，通常存在于groupByKey、reduceByKey等操作，需要对RDD分区做shuffle。
<ul>
<li><strong>ShuffleDependency</strong></li>
</ul>
</li>
<li>窄依赖：父RDD的每个分区，最多被子RDD的一个分区使用。通常存在于map、filter、union等操作，<strong>一个输入分区对应一个输出分区</strong>。
<ul>
<li><strong>OneToOneDependency</strong>、<strong>RangeDependency</strong></li>
</ul>
</li>
</ul>
<p>部分RDD数据丢失时，可以通过依赖关系重新计算，进而恢复丢失数据的分区。</p>
<h3 id="rdd持久化">RDD持久化</h3>
<p>Spark会将RDD持久化到磁盘，当actions算子需要使用时，从磁盘读取，避免重新计算。</p>
<p>可以使用<code>persist()</code>方法来指定持久化。</p>
<p>使用cache的两条基本原则：</p>
<ol>
<li>如果RDD在应用中的引用次数为1，不使用cache</li>
<li>如果引用次数大于1，并且运行成本占比超过30%，考虑启用cache</li>
</ol>
<table>
  <thead>
      <tr>
          <th><strong>持久化级别</strong></th>
          <th><strong>含义</strong></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>MEMORY_ONLY</td>
          <td>将 RDD 以反序列化 Java 对象的形式存储在 JVM 中，如果大小超过可用内存，则超出部分不会缓存，需重新计算</td>
      </tr>
      <tr>
          <td>MEMORY_AND_DISK</td>
          <td>将 RDD 以反序列化 Java 对象的形式存储在 JVM 中，如果大小超过可用内存，则超出部分会存在在磁盘上，当需要时从磁盘读取</td>
      </tr>
      <tr>
          <td>DISK_ONLY</td>
          <td>将所有 RDD 分区存储到磁盘上</td>
      </tr>
      <tr>
          <td>MEMORY_ONLY_SER</td>
          <td>将 RDD 以序列化 Java 对象的形式存储在 JVM 中，具有更好的空间利用率，但是需要占用更多的 CPU 资源</td>
      </tr>
      <tr>
          <td>MEMORY_AND_DISK_SER</td>
          <td>将 RDD 以序列化 Java 对象的形式存储在 JVM 中，如果大小超过可用内存，则超出部分会存在在磁盘上，无需重新计算</td>
      </tr>
      <tr>
          <td>MEMORY_ONLY_2</td>
          <td>与 MEMORY_ONLY 级别相同，存在副本</td>
      </tr>
      <tr>
          <td>MEMORY_AND_DISK_2</td>
          <td>与 MEMORY_AND_DISK 级别相同，存在副本</td>
      </tr>
  </tbody>
</table>
<h3 id="rdd-checkpoint">RDD Checkpoint</h3>
<p>RDD Checkpoint是一种容错保障机制，由<code>checkpoint()</code>触发，主要执行：</p>
<ol>
<li>重新计算调用了<code>checkpoint()</code>的RDD，并将结果保存到存储系统，可以通过<code>sc.setCheckpointDir(&quot;checkpoint&quot;)</code>修改存储地址</li>
<li>切断原有的依赖血缘关系</li>
</ol>
<p>与持久化有所区别：</p>
<table>
  <thead>
      <tr>
          <th>区别项</th>
          <th>RDD 持久化</th>
          <th>RDD 检查点</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>生命周期</td>
          <td>应用结束便删除</td>
          <td>永久保存</td>
      </tr>
      <tr>
          <td>血缘关系</td>
          <td>不切断</td>
          <td>切断</td>
      </tr>
      <tr>
          <td>使用场景</td>
          <td>支持在同一个应用中复用计算结果</td>
          <td>支持在多个应用中复用计算结果</td>
      </tr>
  </tbody>
</table>
<p>checkpoint在任务执行结束后触发：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-scala" data-lang="scala"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> runJob<span style="color:#f92672">[</span><span style="color:#66d9ef">T</span>, <span style="color:#66d9ef">U:</span> <span style="color:#66d9ef">ClassTag</span><span style="color:#f92672">](</span>  
</span></span><span style="display:flex;"><span>rdd<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">RDD</span><span style="color:#f92672">[</span><span style="color:#66d9ef">T</span><span style="color:#f92672">],</span>  
</span></span><span style="display:flex;"><span>func<span style="color:#66d9ef">:</span> <span style="color:#f92672">(</span><span style="color:#66d9ef">TaskContext</span><span style="color:#f92672">,</span> <span style="color:#66d9ef">Iterator</span><span style="color:#f92672">[</span><span style="color:#66d9ef">T</span><span style="color:#f92672">])</span> <span style="color:#66d9ef">=&gt;</span> U<span style="color:#f92672">,</span>  
</span></span><span style="display:flex;"><span>partitions<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">Seq</span><span style="color:#f92672">[</span><span style="color:#66d9ef">Int</span><span style="color:#f92672">],</span>  
</span></span><span style="display:flex;"><span>resultHandler<span style="color:#66d9ef">:</span> <span style="color:#f92672">(</span><span style="color:#66d9ef">Int</span><span style="color:#f92672">,</span> <span style="color:#66d9ef">U</span><span style="color:#f92672">)</span> <span style="color:#66d9ef">=&gt;</span> <span style="color:#a6e22e">Unit</span><span style="color:#f92672">)</span><span style="color:#66d9ef">:</span> <span style="color:#66d9ef">Unit</span> <span style="color:#f92672">=</span> <span style="color:#f92672">{</span>  
</span></span><span style="display:flex;"><span><span style="color:#75715e">// ...  
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>dagScheduler<span style="color:#f92672">.</span>runJob<span style="color:#f92672">(</span>rdd<span style="color:#f92672">,</span> cleanedFunc<span style="color:#f92672">,</span> partitions<span style="color:#f92672">,</span> callSite<span style="color:#f92672">,</span> resultHandler<span style="color:#f92672">,</span> localProperties<span style="color:#f92672">.</span>get<span style="color:#f92672">)</span>  
</span></span><span style="display:flex;"><span>progressBar<span style="color:#f92672">.</span>foreach<span style="color:#f92672">(</span><span style="color:#66d9ef">_</span><span style="color:#f92672">.</span>finishAll<span style="color:#f92672">())</span>  
</span></span><span style="display:flex;"><span><span style="color:#f92672">**</span>rdd<span style="color:#f92672">.</span>doCheckpoint<span style="color:#f92672">()**</span>  
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span></code></pre></div><h2 id="共享变量">共享变量</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-scala" data-lang="scala"><span style="display:flex;"><span><span style="color:#66d9ef">val</span> rdd<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">RDD</span><span style="color:#f92672">[</span><span style="color:#66d9ef">Int</span><span style="color:#f92672">]</span> <span style="color:#66d9ef">=</span> sc<span style="color:#f92672">.</span>makeRDD<span style="color:#f92672">(</span><span style="color:#a6e22e">List</span><span style="color:#f92672">(</span><span style="color:#ae81ff">1</span><span style="color:#f92672">,</span> <span style="color:#ae81ff">2</span><span style="color:#f92672">,</span> <span style="color:#ae81ff">3</span><span style="color:#f92672">,</span> <span style="color:#ae81ff">4</span><span style="color:#f92672">))</span>  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">var</span> sum<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">Int</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>  
</span></span><span style="display:flex;"><span>rdd<span style="color:#f92672">.</span>foreach<span style="color:#f92672">(</span>num <span style="color:#66d9ef">=&gt;</span> <span style="color:#f92672">{</span>  
</span></span><span style="display:flex;"><span>sum <span style="color:#f92672">+=</span> num  
</span></span><span style="display:flex;"><span><span style="color:#f92672">})</span>  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>println<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;sum =&gt; &#34;</span> <span style="color:#f92672">+</span> sum<span style="color:#f92672">)</span>
</span></span></code></pre></div><p>上述代码提交到Spark执行，sum最终结果为0，这是因为计算逻辑是分发到Executor执行的，Executor将计算结果返回给Driver时，不会将非RDD内部数据的普通变量返回，也就是<code>sum</code>并没有参与计算。</p>
<p>为了解决上述问题，Spark引入了累加器和广播变量。</p>
<h3 id="累加器accumulators">累加器（Accumulators）</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-scala" data-lang="scala"><span style="display:flex;"><span><span style="color:#66d9ef">val</span> rdd<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">RDD</span><span style="color:#f92672">[</span><span style="color:#66d9ef">Int</span><span style="color:#f92672">]</span> <span style="color:#66d9ef">=</span> sc<span style="color:#f92672">.</span>makeRDD<span style="color:#f92672">(</span><span style="color:#a6e22e">List</span><span style="color:#f92672">(</span><span style="color:#ae81ff">1</span><span style="color:#f92672">,</span> <span style="color:#ae81ff">2</span><span style="color:#f92672">,</span> <span style="color:#ae81ff">3</span><span style="color:#f92672">,</span> <span style="color:#ae81ff">4</span><span style="color:#f92672">))</span>  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">val</span> sumAccumulator<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">LongAccumulator</span> <span style="color:#f92672">=</span> sc<span style="color:#f92672">.</span>longAccumulator<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;sum&#34;</span><span style="color:#f92672">)</span>  
</span></span><span style="display:flex;"><span>rdd<span style="color:#f92672">.</span>foreach<span style="color:#f92672">(</span>num <span style="color:#66d9ef">=&gt;</span> <span style="color:#f92672">{</span>  
</span></span><span style="display:flex;"><span>sumAccumulator<span style="color:#f92672">.</span>add<span style="color:#f92672">(</span>num<span style="color:#f92672">)</span>  
</span></span><span style="display:flex;"><span><span style="color:#f92672">})</span>  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>println<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;sum =&gt; &#34;</span> <span style="color:#f92672">+</span> sumAccumulator<span style="color:#f92672">.</span>value<span style="color:#f92672">)</span>
</span></span></code></pre></div><h3 id="广播变量">广播变量</h3>
<p>多个Task需要共享同一个大型变量时，可以使用广播变量优化。广播变量会通过Driver分发到每一个Executor中。普通变量分发到具体的Task中。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-scala" data-lang="scala"><span style="display:flex;"><span><span style="color:#75715e">// 创建单词列表list 
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">val</span> list<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">List</span><span style="color:#f92672">[</span><span style="color:#66d9ef">String</span><span style="color:#f92672">]</span> <span style="color:#66d9ef">=</span> <span style="color:#a6e22e">List</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;Apache&#34;</span><span style="color:#f92672">,</span> <span style="color:#e6db74">&#34;Spark&#34;</span><span style="color:#f92672">)</span> 
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 创建广播变量bc 
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">val</span> bc <span style="color:#66d9ef">=</span> sc<span style="color:#f92672">.</span>broadcast<span style="color:#f92672">(</span>list<span style="color:#f92672">)</span>
</span></span></code></pre></div><p><code>spark.sql.autoBroadcastJoinThreshold</code>：数据表采用Broadcast Join的最低阈值，默认10MB</p>
<h2 id="spark调度模块">Spark调度模块</h2>
<table>
  <thead>
      <tr>
          <th>关键步骤</th>
          <th>所在进程</th>
          <th>核心组件</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>将DAG拆分为不同的Stages，根据Stages创建分布式任务Tasks和任务组TaskSets</td>
          <td>Driver</td>
          <td>DAGScheduler</td>
      </tr>
      <tr>
          <td>获取集群内可用计算资源</td>
          <td>Driver</td>
          <td>SchedulerBackend</td>
      </tr>
      <tr>
          <td>根据调度规则决定任务优先级，完成任务调度</td>
          <td>Driver</td>
          <td>TaskScheduler</td>
      </tr>
      <tr>
          <td>依次将分布式任务发送到Executors</td>
          <td>Driver</td>
          <td>SchedulerBackend</td>
      </tr>
      <tr>
          <td>执行收到的分布式任务</td>
          <td>Executors</td>
          <td>ExecutorBackend</td>
      </tr>
      <tr>
          <td></td>
          <td></td>
          <td></td>
      </tr>
  </tbody>
</table>
<p>拆分Stages规则：以Actions算子为起点，从后向前回溯DAG，以Shuffle操作为边界去划分Stages。</p>
<h3 id="schedulerbackend">SchedulerBackend</h3>
<p>SchedulerBackend：对资源调度器的抽象，为Standalone、Yarn等方式提供了对应的实现类。实现上内部使用ExecutorDataMap映射存储Executor的信息，包括RPC地址、CPU核数等信息。</p>
<h3 id="taskscheduler">TaskScheduler</h3>
<p>TaskScheduler的调度策略分为两个层次：</p>
<ol>
<li>不同Stages之间的调度优先级</li>
<li>Stages内不同任务之间的调度优先级</li>
</ol>
<p>Stages之间的任务调度，支持两种调度模式：FIFO、FAIR（用户定义优先级）</p>
<h2 id="内存管理">内存管理</h2>
<p>Spark Executor会将内存划分成四个区域：</p>
<ul>
<li>Reserved Memory：固定为300MB，Spark预留空间，用于存储Spark内部对象</li>
<li>User Memory：存储程序自定义的数据对象。</li>
<li>Execution Memory：用于执行任务计算，包括数据转换、过滤、排序、聚合等。</li>
<li>Storage Memory：用于缓存分布式数据集，比如RDD Cache（持久化内存），广播变量等。</li>
</ul>
<p>Execution Memory和Storage Memory可以相互抢占空间（对方内存有空闲即可），若被抢占方有内存需求时，需要归还。Execution Memory抢占的空间需要等分布式任务执行完毕后才能归还。</p>
<h3 id="内存配置项">内存配置项</h3>
<p><img src="https://blog-1251613845.cos.ap-shanghai.myqcloud.com/20240912195907.png" alt="image.png"></p>
<ul>
<li>spark.executor.memory（绝对值）：指定了Executor进程的JVM堆内存大小</li>
<li>spark.memory.fraction（比例）：Execution Memory和Storage Memory两部分区域</li>
<li>spark.memory.storageFraction（比例）：区分Execution Memory和Storage Memory的初始大小</li>
</ul>
<h2 id="spark-streaming">Spark Streaming</h2>
<p>Spark Streaming是基于Spark Core实现的流式计算框架。</p>
<p>从实现上来看，并不是真正的流式计算，而是将数据包装成一批数据（Mirco Batch），从而达到类似流式计算的效果。</p>
<p><img src="https://blog-1251613845.cos.ap-shanghai.myqcloud.com/20240731141319.png" alt="image.png"></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-scala" data-lang="scala"><span style="display:flex;"><span><span style="color:#66d9ef">object</span> <span style="color:#a6e22e">WordCountStream</span> <span style="color:#f92672">{</span>  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> main<span style="color:#f92672">(</span>args<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">Array</span><span style="color:#f92672">[</span><span style="color:#66d9ef">String</span><span style="color:#f92672">])</span><span style="color:#66d9ef">:</span> <span style="color:#66d9ef">Unit</span> <span style="color:#f92672">=</span> <span style="color:#f92672">{</span>  
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 1. 设置运行模式为 local，线程数为 3  
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">val</span> conf<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">SparkConf</span> <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> <span style="color:#a6e22e">SparkConf</span><span style="color:#f92672">().</span>setMaster<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;local[3]&#34;</span><span style="color:#f92672">).</span>setAppName<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;Word Count Streaming App&#34;</span><span style="color:#f92672">)</span>  
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 2. 创建批次周期为 10s 的 StreamingContext  
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">val</span> ssc<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">StreamingContext</span> <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> <span style="color:#a6e22e">StreamingContext</span><span style="color:#f92672">(</span>conf<span style="color:#f92672">,</span> <span style="color:#a6e22e">Seconds</span><span style="color:#f92672">(</span><span style="color:#ae81ff">10</span><span style="color:#f92672">))</span>  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 3. 创建来自于本地 9999 端口的 Dtream 对象  
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">val</span> inputStream<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">ReceiverInputDStream</span><span style="color:#f92672">[</span><span style="color:#66d9ef">String</span><span style="color:#f92672">]</span> <span style="color:#66d9ef">=</span> ssc<span style="color:#f92672">.</span>socketTextStream<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;localhost&#34;</span><span style="color:#f92672">,</span> <span style="color:#ae81ff">9999</span><span style="color:#f92672">)</span>  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 4. 定义 DStream 转换算子  
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">val</span> wcStream<span style="color:#66d9ef">:</span> <span style="color:#66d9ef">DStream</span><span style="color:#f92672">[(</span><span style="color:#66d9ef">String</span>, <span style="color:#66d9ef">Int</span><span style="color:#f92672">)]</span> <span style="color:#66d9ef">=</span> inputStream  
</span></span><span style="display:flex;"><span><span style="color:#f92672">.</span>flatMap<span style="color:#f92672">(</span><span style="color:#66d9ef">_</span><span style="color:#f92672">.</span>split<span style="color:#f92672">(</span><span style="color:#e6db74">&#34; &#34;</span><span style="color:#f92672">))</span>  
</span></span><span style="display:flex;"><span><span style="color:#f92672">.</span>map<span style="color:#f92672">(</span>word <span style="color:#66d9ef">=&gt;</span> <span style="color:#f92672">(</span>word<span style="color:#f92672">,</span> <span style="color:#ae81ff">1</span><span style="color:#f92672">))</span>  
</span></span><span style="display:flex;"><span><span style="color:#f92672">.</span>reduceByKey<span style="color:#f92672">(</span><span style="color:#66d9ef">_</span> <span style="color:#f92672">+</span> <span style="color:#66d9ef">_</span><span style="color:#f92672">)</span>  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 5. 定义 DStream 输出算子  
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>wcStream<span style="color:#f92672">.</span>print<span style="color:#f92672">()</span>  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 6. 启动计算作业  
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>ssc<span style="color:#f92672">.</span>start<span style="color:#f92672">()</span>  
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 7. 进行阻塞，防止 Driver 进程退出  
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>ssc<span style="color:#f92672">.</span>awaitTermination<span style="color:#f92672">()</span>  
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>  
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span></code></pre></div>
        </div>

        <div class="row middle-xs">
          <div class="col-xs-12">
            
          </div>
        </div>
        
          <div class="row">
            <div class="col-xs-12">
              
            </div>
          </div>

          



          
          
          <div style="height: 50px;"></div>
          
        

        <div class="site-footer">
  
  
</div>

      </div>
    </div>
  </article>

  

<script>
  
  
    
    
  
</script>

  

</body>

</html>