<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kafka on l1nker4&#39;s Blog</title>
    <link>https://example.org/categories/kafka/</link>
    <description>Recent content in Kafka on l1nker4&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 05 Jan 2025 21:47:13 +0800</lastBuildDate>
    <atom:link href="https://example.org/categories/kafka/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kafka源码分析(一)- clients模块</title>
      <link>https://example.org/posts/%E4%B8%AD%E9%97%B4%E4%BB%B6/kafka/kafka-source-code-clients/</link>
      <pubDate>Sun, 05 Jan 2025 21:47:13 +0800</pubDate>
      <guid>https://example.org/posts/%E4%B8%AD%E9%97%B4%E4%BB%B6/kafka/kafka-source-code-clients/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;clients模块是Kafka官方提供的默认Java客户端，该模块分为三部分：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Admin：提供了管理topic、partition、config的相关API&lt;/li&gt;&#xA;&lt;li&gt;Consumer：提供了消费topic的API&lt;/li&gt;&#xA;&lt;li&gt;Producer：提供了向topic投递消息的功能&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Kafka源码以3.9为例。&lt;/p&gt;&#xA;&lt;h2 id=&#34;producer&#34;&gt;Producer&lt;/h2&gt;&#xA;&lt;h3 id=&#34;send流程&#34;&gt;send流程&lt;/h3&gt;&#xA;&lt;p&gt;send支持异步方式向Kafka broker端发送消息，并有后台sender线程按批向broker写入。&lt;/p&gt;&#xA;&lt;h4 id=&#34;interceptor机制&#34;&gt;interceptor机制&lt;/h4&gt;&#xA;&lt;p&gt;send流程中首先会检查用户是否自定义interceptor实现，用于处理send前置逻辑，具体业务场景不多赘述。&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;@Override&lt;/span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; Future&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;RecordMetadata&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;send&lt;/span&gt;(ProducerRecord&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;K, V&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; record, Callback callback) {  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 拦截器前置send动作  &lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ProducerRecord&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;K, V&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; interceptedRecord &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;this&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;interceptors&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;onSend&lt;/span&gt;(record);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; doSend(interceptedRecord, callback);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中ProducerInterceptor提供了以下接口：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ProducerRecord&amp;lt;K, V&amp;gt; onSend(ProducerRecord&amp;lt;K, V&amp;gt; record)：send前置处理逻辑&lt;/li&gt;&#xA;&lt;li&gt;onAcknowledgement(RecordMetadata metadata, Exception exception)：消息被应答之后或发送消息失败时调用。&lt;/li&gt;&#xA;&lt;li&gt;close()：用于关闭interceptor资源。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;自定义interceptor需要考虑线程安全。&lt;/p&gt;&#xA;&lt;h4 id=&#34;dosend流程&#34;&gt;doSend流程&lt;/h4&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;private&lt;/span&gt; Future&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;RecordMetadata&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;doSend&lt;/span&gt;(ProducerRecord&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;K, V&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; record, Callback callback) {  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 1.1 创建callback对象  &lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    AppendCallbacks appendCallbacks &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;new&lt;/span&gt; AppendCallbacks(callback, &lt;span style=&#34;color:#66d9ef&#34;&gt;this&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;interceptors&lt;/span&gt;, record);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt; {  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;//1.2 检查producer是否被close  &lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        throwIfProducerClosed();  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;// first make sure the metadata for the topic is available  &lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;long&lt;/span&gt; nowMs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time.&lt;span style=&#34;color:#a6e22e&#34;&gt;milliseconds&lt;/span&gt;();  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        ClusterAndWaitTime clusterAndWaitTime;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;//1.3 拉取指定topic、分区的元数据，和等待时间  &lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt; {  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            clusterAndWaitTime &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; waitOnMetadata(record.&lt;span style=&#34;color:#a6e22e&#34;&gt;topic&lt;/span&gt;(), record.&lt;span style=&#34;color:#a6e22e&#34;&gt;partition&lt;/span&gt;(), nowMs, maxBlockTimeMs);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        } &lt;span style=&#34;color:#66d9ef&#34;&gt;catch&lt;/span&gt; (KafkaException e) {  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (metadata.&lt;span style=&#34;color:#a6e22e&#34;&gt;isClosed&lt;/span&gt;())  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#66d9ef&#34;&gt;throw&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;new&lt;/span&gt; KafkaException(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Producer closed while send in progress&amp;#34;&lt;/span&gt;, e);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;throw&lt;/span&gt; e;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        }  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        nowMs &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; clusterAndWaitTime.&lt;span style=&#34;color:#a6e22e&#34;&gt;waitedOnMetadataMs&lt;/span&gt;;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;long&lt;/span&gt; remainingWaitMs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Math.&lt;span style=&#34;color:#a6e22e&#34;&gt;max&lt;/span&gt;(0, maxBlockTimeMs &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; clusterAndWaitTime.&lt;span style=&#34;color:#a6e22e&#34;&gt;waitedOnMetadataMs&lt;/span&gt;);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        Cluster cluster &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; clusterAndWaitTime.&lt;span style=&#34;color:#a6e22e&#34;&gt;cluster&lt;/span&gt;;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;//1.4 key value进行序列化  &lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;byte&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[]&lt;/span&gt; serializedKey;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt; {  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            serializedKey &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; keySerializer.&lt;span style=&#34;color:#a6e22e&#34;&gt;serialize&lt;/span&gt;(record.&lt;span style=&#34;color:#a6e22e&#34;&gt;topic&lt;/span&gt;(), record.&lt;span style=&#34;color:#a6e22e&#34;&gt;headers&lt;/span&gt;(), record.&lt;span style=&#34;color:#a6e22e&#34;&gt;key&lt;/span&gt;());  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        } &lt;span style=&#34;color:#66d9ef&#34;&gt;catch&lt;/span&gt; (ClassCastException cce) {  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;throw&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;new&lt;/span&gt; SerializationException(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Can&amp;#39;t convert key of class &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; record.&lt;span style=&#34;color:#a6e22e&#34;&gt;key&lt;/span&gt;().&lt;span style=&#34;color:#a6e22e&#34;&gt;getClass&lt;/span&gt;().&lt;span style=&#34;color:#a6e22e&#34;&gt;getName&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; to class &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; producerConfig.&lt;span style=&#34;color:#a6e22e&#34;&gt;getClass&lt;/span&gt;(ProducerConfig.&lt;span style=&#34;color:#a6e22e&#34;&gt;KEY_SERIALIZER_CLASS_CONFIG&lt;/span&gt;).&lt;span style=&#34;color:#a6e22e&#34;&gt;getName&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; specified in key.serializer&amp;#34;&lt;/span&gt;, cce);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        }  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;byte&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[]&lt;/span&gt; serializedValue;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt; {  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            serializedValue &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; valueSerializer.&lt;span style=&#34;color:#a6e22e&#34;&gt;serialize&lt;/span&gt;(record.&lt;span style=&#34;color:#a6e22e&#34;&gt;topic&lt;/span&gt;(), record.&lt;span style=&#34;color:#a6e22e&#34;&gt;headers&lt;/span&gt;(), record.&lt;span style=&#34;color:#a6e22e&#34;&gt;value&lt;/span&gt;());  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        } &lt;span style=&#34;color:#66d9ef&#34;&gt;catch&lt;/span&gt; (ClassCastException cce) {  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;throw&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;new&lt;/span&gt; SerializationException(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Can&amp;#39;t convert value of class &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; record.&lt;span style=&#34;color:#a6e22e&#34;&gt;value&lt;/span&gt;().&lt;span style=&#34;color:#a6e22e&#34;&gt;getClass&lt;/span&gt;().&lt;span style=&#34;color:#a6e22e&#34;&gt;getName&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; to class &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; producerConfig.&lt;span style=&#34;color:#a6e22e&#34;&gt;getClass&lt;/span&gt;(ProducerConfig.&lt;span style=&#34;color:#a6e22e&#34;&gt;VALUE_SERIALIZER_CLASS_CONFIG&lt;/span&gt;).&lt;span style=&#34;color:#a6e22e&#34;&gt;getName&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; specified in value.serializer&amp;#34;&lt;/span&gt;, cce);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        }  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;// 1.5 计算当前消息所属的partition  &lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; partition &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; partition(record, serializedKey, serializedValue, cluster);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;// 1.6 设置消息header为readOnly  &lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        setReadOnly(record.&lt;span style=&#34;color:#a6e22e&#34;&gt;headers&lt;/span&gt;());  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        Header&lt;span style=&#34;color:#f92672&#34;&gt;[]&lt;/span&gt; headers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; record.&lt;span style=&#34;color:#a6e22e&#34;&gt;headers&lt;/span&gt;().&lt;span style=&#34;color:#a6e22e&#34;&gt;toArray&lt;/span&gt;();  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;//1.7 检查消息大小是否符合  &lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; serializedSize &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; AbstractRecords.&lt;span style=&#34;color:#a6e22e&#34;&gt;estimateSizeInBytesUpperBound&lt;/span&gt;(apiVersions.&lt;span style=&#34;color:#a6e22e&#34;&gt;maxUsableProduceMagic&lt;/span&gt;(),  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                compression.&lt;span style=&#34;color:#a6e22e&#34;&gt;type&lt;/span&gt;(), serializedKey, serializedValue, headers);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        ensureValidRecordSize(serializedSize);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;long&lt;/span&gt; timestamp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; record.&lt;span style=&#34;color:#a6e22e&#34;&gt;timestamp&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;?&lt;/span&gt; nowMs : record.&lt;span style=&#34;color:#a6e22e&#34;&gt;timestamp&lt;/span&gt;();  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;// 自定义partitioner  &lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;boolean&lt;/span&gt; abortOnNewBatch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; partitioner &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;// 1.8 将消息追加到accumulator中  &lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        RecordAccumulator.&lt;span style=&#34;color:#a6e22e&#34;&gt;RecordAppendResult&lt;/span&gt; result &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; accumulator.&lt;span style=&#34;color:#a6e22e&#34;&gt;append&lt;/span&gt;(record.&lt;span style=&#34;color:#a6e22e&#34;&gt;topic&lt;/span&gt;(), partition, timestamp, serializedKey,  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                serializedValue, headers, appendCallbacks, remainingWaitMs, abortOnNewBatch, nowMs, cluster);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;assert&lt;/span&gt; appendCallbacks.&lt;span style=&#34;color:#a6e22e&#34;&gt;getPartition&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; RecordMetadata.&lt;span style=&#34;color:#a6e22e&#34;&gt;UNKNOWN_PARTITION&lt;/span&gt;;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;// 1.9 消息入新batch的情况  &lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (result.&lt;span style=&#34;color:#a6e22e&#34;&gt;abortForNewBatch&lt;/span&gt;) {  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; prevPartition &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; partition;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            onNewBatch(record.&lt;span style=&#34;color:#a6e22e&#34;&gt;topic&lt;/span&gt;(), cluster, prevPartition);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            partition &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; partition(record, serializedKey, serializedValue, cluster);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (log.&lt;span style=&#34;color:#a6e22e&#34;&gt;isTraceEnabled&lt;/span&gt;()) {  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                log.&lt;span style=&#34;color:#a6e22e&#34;&gt;trace&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Retrying append due to new batch creation for topic {} partition {}. The old partition was {}&amp;#34;&lt;/span&gt;, record.&lt;span style=&#34;color:#a6e22e&#34;&gt;topic&lt;/span&gt;(), partition, prevPartition);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            }  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            result &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; accumulator.&lt;span style=&#34;color:#a6e22e&#34;&gt;append&lt;/span&gt;(record.&lt;span style=&#34;color:#a6e22e&#34;&gt;topic&lt;/span&gt;(), partition, timestamp, serializedKey,  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                serializedValue, headers, appendCallbacks, remainingWaitMs, &lt;span style=&#34;color:#66d9ef&#34;&gt;false&lt;/span&gt;, nowMs, cluster);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        }  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;// 2.1 开启事务的情况  &lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (transactionManager &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;) {  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            transactionManager.&lt;span style=&#34;color:#a6e22e&#34;&gt;maybeAddPartition&lt;/span&gt;(appendCallbacks.&lt;span style=&#34;color:#a6e22e&#34;&gt;topicPartition&lt;/span&gt;());  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        }  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;// 2.2 如果batch满了，或者新batch被创建，唤醒后台sender线程  &lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (result.&lt;span style=&#34;color:#a6e22e&#34;&gt;batchIsFull&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;||&lt;/span&gt; result.&lt;span style=&#34;color:#a6e22e&#34;&gt;newBatchCreated&lt;/span&gt;) {  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            log.&lt;span style=&#34;color:#a6e22e&#34;&gt;trace&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Waking up the sender since topic {} partition {} is either full or getting a new batch&amp;#34;&lt;/span&gt;, record.&lt;span style=&#34;color:#a6e22e&#34;&gt;topic&lt;/span&gt;(), appendCallbacks.&lt;span style=&#34;color:#a6e22e&#34;&gt;getPartition&lt;/span&gt;());  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;this&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;sender&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;wakeup&lt;/span&gt;();  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        }  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; result.&lt;span style=&#34;color:#a6e22e&#34;&gt;future&lt;/span&gt;;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;// handling exceptions and record the errors;  &lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;// for API exceptions return them in the future,        // for other exceptions throw directly    } catch (ApiException e) {  &lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        log.&lt;span style=&#34;color:#a6e22e&#34;&gt;debug&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Exception occurred during message send:&amp;#34;&lt;/span&gt;, e);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (callback &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;) {  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            TopicPartition tp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; appendCallbacks.&lt;span style=&#34;color:#a6e22e&#34;&gt;topicPartition&lt;/span&gt;();  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            RecordMetadata nullMetadata &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;new&lt;/span&gt; RecordMetadata(tp, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;1, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;1, RecordBatch.&lt;span style=&#34;color:#a6e22e&#34;&gt;NO_TIMESTAMP&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;1, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;1);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            callback.&lt;span style=&#34;color:#a6e22e&#34;&gt;onCompletion&lt;/span&gt;(nullMetadata, e);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        }  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;this&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;errors&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;record&lt;/span&gt;();  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;this&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;interceptors&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;onSendError&lt;/span&gt;(record, appendCallbacks.&lt;span style=&#34;color:#a6e22e&#34;&gt;topicPartition&lt;/span&gt;(), e);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (transactionManager &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;) {  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            transactionManager.&lt;span style=&#34;color:#a6e22e&#34;&gt;maybeTransitionToErrorState&lt;/span&gt;(e);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        }  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;new&lt;/span&gt; FutureFailure(e);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    } &lt;span style=&#34;color:#66d9ef&#34;&gt;catch&lt;/span&gt; (InterruptedException e) {  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;this&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;errors&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;record&lt;/span&gt;();  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;this&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;interceptors&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;onSendError&lt;/span&gt;(record, appendCallbacks.&lt;span style=&#34;color:#a6e22e&#34;&gt;topicPartition&lt;/span&gt;(), e);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;throw&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;new&lt;/span&gt; InterruptException(e);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    } &lt;span style=&#34;color:#66d9ef&#34;&gt;catch&lt;/span&gt; (KafkaException e) {  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;this&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;errors&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;record&lt;/span&gt;();  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;this&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;interceptors&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;onSendError&lt;/span&gt;(record, appendCallbacks.&lt;span style=&#34;color:#a6e22e&#34;&gt;topicPartition&lt;/span&gt;(), e);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;throw&lt;/span&gt; e;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    } &lt;span style=&#34;color:#66d9ef&#34;&gt;catch&lt;/span&gt; (Exception e) {  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;// we notify interceptor about all exceptions, since onSend is called before anything else in this method  &lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;this&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;interceptors&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;onSendError&lt;/span&gt;(record, appendCallbacks.&lt;span style=&#34;color:#a6e22e&#34;&gt;topicPartition&lt;/span&gt;(), e);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;throw&lt;/span&gt; e;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;partition机制&#34;&gt;partition机制&lt;/h4&gt;&#xA;&lt;p&gt;Producer中计算消息partition的流程较为简单：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kafka学习笔记(四)-集群工作机制</title>
      <link>https://example.org/posts/%E4%B8%AD%E9%97%B4%E4%BB%B6/kafka/kafka%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9B%9B-%E9%9B%86%E7%BE%A4%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/</link>
      <pubDate>Wed, 06 Jul 2022 18:49:22 +0000</pubDate>
      <guid>https://example.org/posts/%E4%B8%AD%E9%97%B4%E4%BB%B6/kafka/kafka%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9B%9B-%E9%9B%86%E7%BE%A4%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/</guid>
      <description>&lt;h2 id=&#34;controller机制&#34;&gt;Controller机制&lt;/h2&gt;&#xA;&lt;p&gt;Controller主要作用是在Zookeeper的帮助下管理和协调整个Kafka集群（在zk中存储集群元数据）。Kafka集群中会有一个或多个Broker，其中一个Broker会被选举为Controller，它负责管理整个集群中所有分区和副本的状态，其工作职责包括以下内容：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Topic管理&lt;/strong&gt;：完成对Kafka的Topic的创建删除、分区增加等操作。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;分区重分配&lt;/strong&gt;：新的Broker加入集群时，不会自动分担已有的topic负载，只会对后续的topic生效，此时如果需要对已有topic负载，需要用户手动进行&lt;strong&gt;分区重分配&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Leader选举&lt;/strong&gt;：负责Partition Leader选举的工作&lt;/li&gt;&#xA;&lt;li&gt;集群成员管理：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Kafka 使用Zookeeper的临时节点来选举Controller&lt;/li&gt;&#xA;&lt;li&gt;Zookeeper在Broker加入集群或退出集群时通知Controller&lt;/li&gt;&#xA;&lt;li&gt;Controller负责在Broker加入或离开集群时进行分区Leader选举&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;元数据管理：Controller负责管理集群中所有的元数据&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Controller选举流程：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;每个Broker启动时，都会尝试读取&lt;code&gt;/controller&lt;/code&gt;节点的brokerid的值，如果值不为-1，则表明已经有其他broker节点成为Controller，当前broker放弃选举&lt;/li&gt;&#xA;&lt;li&gt;如果不存在&lt;code&gt;/controller&lt;/code&gt;节点或节点数据异常，则主动创建节点并存储brokerid&lt;/li&gt;&#xA;&lt;li&gt;其他broker会将选举成功的Brokerid都在内存保存下来&lt;/li&gt;&#xA;&lt;li&gt;同时使用&lt;code&gt;/controller_epoch&lt;/code&gt;持久性节点来记录任期号，记录Controller发生变化的次数，类似于Raft中的任期。&#xA;&lt;ul&gt;&#xA;&lt;li&gt;初始值为1，每个与Controller交互的请求都会携带&lt;code&gt;controller_epoch&lt;/code&gt;，如果请求的&lt;code&gt;controller_epoch&lt;/code&gt;大于内存中&lt;code&gt;controller_epoch&lt;/code&gt;，说明内存中的值过期了，目前已有新的Controller当选。&lt;/li&gt;&#xA;&lt;li&gt;由两部分组成：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;epoch：单调递增的版本号，leader发生变更，进行自增&lt;/li&gt;&#xA;&lt;li&gt;start offset：Leader副本在该Epoch值上写入的首条消息的位移。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;每个分区都缓存该值，并定期持久化到&lt;code&gt;checkpoint&lt;/code&gt;文件中&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;partition-leader选举&#34;&gt;Partition Leader选举&lt;/h3&gt;&#xA;&lt;p&gt;Controller拥有选举分区Leader的功能，每个分区都会有一个Broker作为Leader，处理所有的读写请求，选举流程由Controller负责：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Controller从ZK中读取当前分区所有的ISR集合&lt;/li&gt;&#xA;&lt;li&gt;调用配置的分区选择算法选举分区的Leader&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;code&gt;Partition Leader&lt;/code&gt;的定义如下：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Each partition has one server which acts as the &amp;ldquo;leader&amp;rdquo; and zero or more servers which act as &amp;ldquo;followers&amp;rdquo;. The leader handles all read and write requests for the partition while the followers passively replicate the leader. If the leader fails, one of the followers will automatically become the new leader. Each server acts as a leader for some of its partitions and a follower for others so load is well balanced within the cluster.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kafka学习笔记(三)-通信协议</title>
      <link>https://example.org/posts/%E4%B8%AD%E9%97%B4%E4%BB%B6/kafka/kafka%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%89-%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE/</link>
      <pubDate>Sun, 03 Jul 2022 10:49:22 +0000</pubDate>
      <guid>https://example.org/posts/%E4%B8%AD%E9%97%B4%E4%BB%B6/kafka/kafka%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%89-%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE/</guid>
      <description>&lt;h2 id=&#34;协议设计&#34;&gt;协议设计&lt;/h2&gt;&#xA;&lt;p&gt;需要进行网络传输的中间件都会拥有自己的一套通信协议，这往往会成为该组件的性能瓶颈，需要考虑的优化点较多。Kafka自定义了基于TCP的二进制通信协议，Kafka2.0中，一共有43种协议类型，每个都有对应的请求和响应，与HTTP协议类似，它同样有&lt;code&gt;RequestHeader&lt;/code&gt;和&lt;code&gt;RequestBody&lt;/code&gt;。其中&lt;code&gt;RequestHeader&lt;/code&gt;结构如下：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;api_key：API标识，例如PRODUCE、FETCH等，用于分别请求的作用。&lt;/li&gt;&#xA;&lt;li&gt;api_version：API版本号&lt;/li&gt;&#xA;&lt;li&gt;correlation_id：客户端指定的唯一标识，服务端返回响应需要将该字段返回以此对应。&lt;/li&gt;&#xA;&lt;li&gt;client_id：客户端id&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Kafka除了提供基本数据类型，还提供了以下的特有类型：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;nullable_string：可为空的字符串类型，若为空用-1表示&lt;/li&gt;&#xA;&lt;li&gt;bytes：表示字节序列，开头是数据长度N（int32表示），后面是N个字节&lt;/li&gt;&#xA;&lt;li&gt;nullable_bytes：与上述string相同&lt;/li&gt;&#xA;&lt;li&gt;records：表示Kafka中的消息序列&lt;/li&gt;&#xA;&lt;li&gt;array：表示一个给定类型T的数组&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;code&gt;RequestBody&lt;/code&gt;结构如下：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;transactional_id：事务id，不使用事务，此项为null&lt;/li&gt;&#xA;&lt;li&gt;acks：对应客户端的acks参数&lt;/li&gt;&#xA;&lt;li&gt;timeout：超时时间&lt;/li&gt;&#xA;&lt;li&gt;topic_data：要发送的数据集合，array类型&#xA;&lt;ul&gt;&#xA;&lt;li&gt;topic：主题&lt;/li&gt;&#xA;&lt;li&gt;data：数据，array类型&#xA;&lt;ul&gt;&#xA;&lt;li&gt;partition：分区编号&lt;/li&gt;&#xA;&lt;li&gt;record_set：数据&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;code&gt;Response&lt;/code&gt;结构如下：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ResponseHeader&#xA;&lt;ul&gt;&#xA;&lt;li&gt;correlation_id：与请求相对应&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;ResponseBody&#xA;&lt;ul&gt;&#xA;&lt;li&gt;responses：array类型，返回的响应结果&#xA;&lt;ul&gt;&#xA;&lt;li&gt;topic：主题&lt;/li&gt;&#xA;&lt;li&gt;partition_responses：返回结果，array类型&#xA;&lt;ul&gt;&#xA;&lt;li&gt;partition：分区编号&lt;/li&gt;&#xA;&lt;li&gt;error_code：错误码，用来标识错误类型&lt;/li&gt;&#xA;&lt;li&gt;base_offset：消息集的起始偏移量&lt;/li&gt;&#xA;&lt;li&gt;log_append_time：消息写入broker的时间&lt;/li&gt;&#xA;&lt;li&gt;log_start_offset：所在分区起始偏移量&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Kafka学习笔记(二)-存储架构</title>
      <link>https://example.org/posts/%E4%B8%AD%E9%97%B4%E4%BB%B6/kafka/kafka%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%8C-%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/</link>
      <pubDate>Wed, 29 Jun 2022 20:06:22 +0000</pubDate>
      <guid>https://example.org/posts/%E4%B8%AD%E9%97%B4%E4%BB%B6/kafka/kafka%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%8C-%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/</guid>
      <description>&lt;h1 id=&#34;kafka存储架构&#34;&gt;Kafka存储架构&lt;/h1&gt;&#xA;&lt;p&gt;Kafka是为了解决大数据量的实时日志流而产生的，日志流主要特点包括：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;数据实时存储&lt;/li&gt;&#xA;&lt;li&gt;海量数据存储与处理&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Kafka需要保证以下几点：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;存储的主要是消息流&lt;/li&gt;&#xA;&lt;li&gt;要保证海量数据的高效存储&lt;/li&gt;&#xA;&lt;li&gt;要支持海量数据的高效检索&lt;/li&gt;&#xA;&lt;li&gt;要保证数据的安全性和稳定性&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Kafka使用的存储方案是：磁盘顺序写 + 稀疏哈希索引。&lt;/p&gt;&#xA;&lt;h2 id=&#34;日志目录布局&#34;&gt;日志目录布局&lt;/h2&gt;&#xA;&lt;p&gt;Kafka中消息以Topic为单位归类，各个Topic下面分为多个分区，分区中每条消息都会被分配一个唯一的序列号（offset）。日志命名方式为：&lt;code&gt;&amp;lt;topic&amp;gt;-&amp;lt;partition&amp;gt;&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;在不考虑多副本的情况下，一个分区对应一个Log，为了防止Log过大，Kafka引入&lt;code&gt;LogSegment&lt;/code&gt;，将Log切分为多个&lt;code&gt;LogSegment&lt;/code&gt;。其结构如下所示：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Log&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LogSegment：每个 LogSegment 都有一个基准偏移量 baseOffset，用来表示当前 LogSegment中第一条消息的offset。只有最后一个LogSegment才能写入。下述文件根据&lt;code&gt;baseOffset&lt;/code&gt;命名，长度固定为20位数字，没有达到的位数用0填充。&#xA;&lt;ul&gt;&#xA;&lt;li&gt;.log：日志文件&lt;/li&gt;&#xA;&lt;li&gt;.index：偏移量索引文件&lt;/li&gt;&#xA;&lt;li&gt;.timeindex：时间戳索引文件&lt;/li&gt;&#xA;&lt;li&gt;.snapshot：快照索引文件&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;消息格式&#34;&gt;消息格式&lt;/h2&gt;&#xA;&lt;p&gt;消息格式关系到存储性能，比如冗余字段会增加分区的存储空间、网络传输的开销较大。&lt;/p&gt;&#xA;&lt;p&gt;Kafka3.0中将&lt;code&gt;BatchRecords&lt;/code&gt;作为磁盘中的存储单元，一个&lt;code&gt;BatchRecords&lt;/code&gt;中包含多个&lt;code&gt;Record&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;BatchRecords&lt;/code&gt;的格式如下：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;baseOffset: int64&#xA;batchLength: int32&#xA;partitionLeaderEpoch: int32&#xA;magic: int8 (current magic value is 2)&#xA;crc: int32&#xA;attributes: int16&#xA;    bit 0~2:&#xA;        0: no compression&#xA;        1: gzip&#xA;        2: snappy&#xA;        3: lz4&#xA;        4: zstd&#xA;    bit 3: timestampType&#xA;    bit 4: isTransactional (0 means not transactional)&#xA;    bit 5: isControlBatch (0 means not a control batch)&#xA;    bit 6: hasDeleteHorizonMs (0 means baseTimestamp is not set as the delete horizon for compaction)&#xA;    bit 7~15: unused&#xA;lastOffsetDelta: int32&#xA;baseTimestamp: int64&#xA;maxTimestamp: int64&#xA;producerId: int64&#xA;producerEpoch: int16&#xA;baseSequence: int32&#xA;records: [Record]&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;字段解释如下：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kafka学习笔记(一)-基础入门</title>
      <link>https://example.org/posts/%E4%B8%AD%E9%97%B4%E4%BB%B6/kafka/kafka%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%80-%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/</link>
      <pubDate>Fri, 06 May 2022 15:08:22 +0000</pubDate>
      <guid>https://example.org/posts/%E4%B8%AD%E9%97%B4%E4%BB%B6/kafka/kafka%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%80-%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/</guid>
      <description>&lt;h2 id=&#34;简介&#34;&gt;简介&lt;/h2&gt;&#xA;&lt;p&gt;Kafka是由LinkedIn使用Scala语言开发的分布式消息引擎系统，目前已被捐献给Apache基金会，它以高吞吐量、可持久化、流数据处理等特性而被广泛使用。它主要有以下三种主要功能：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;消息中间件：具备常见的消息队列功能：系统解耦、冗余存储、流量削峰填谷、缓冲、异步通信，同时具备消息顺序性保障、回溯消费等功能。&lt;/li&gt;&#xA;&lt;li&gt;数据存储系统：使用Kafka存储各种服务的log，然后统一输出，ELK可使用Kafka进行数据中转。&lt;/li&gt;&#xA;&lt;li&gt;流数据处理平台：与flink、spark、storm等组件整合，提供实时计算。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Kafka支持两种常见消息传输模型：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;点对点模型&lt;/strong&gt;：也称为消息队列模型，系统A发送的消息只能被系统B接收，其它系统读取不到。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;发布/订阅模型&lt;/strong&gt;：使用&lt;code&gt;Topic&lt;/code&gt;接收消息，&lt;code&gt;Publisher&lt;/code&gt;和&lt;code&gt;Subscriber&lt;/code&gt;都可以有多个，可以同时向Topic发送接收消息。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;基本概念&#34;&gt;基本概念&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Kafka体系结构：一个Kafka集群包括若干Producer、Customer、Broker，以及一个Zookeeper集群。&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Broker：服务端由被称为&lt;code&gt;Broker&lt;/code&gt;的服务进程构成，&lt;code&gt;Broker&lt;/code&gt;负责接受和处理客户端请求，以及对消息进行持久化。&#xA;&lt;ul&gt;&#xA;&lt;li&gt;可以简单看作为一个独立的Kafka服务节点（进程示例）&lt;/li&gt;&#xA;&lt;li&gt;Broker层面的领导者被称为Controller&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Producer：客户端节点，发送消息的一方。&lt;/li&gt;&#xA;&lt;li&gt;Customer：客户端节点，接收消息的一方。&lt;/li&gt;&#xA;&lt;li&gt;Customer Group：消费者组内每个消费者负责消费不同分区的数据。一个分区只能由组内一个消费者消费，不同消费组之间互不影响。&lt;/li&gt;&#xA;&lt;li&gt;&lt;!-- raw HTML omitted --&gt;Zookeeper集群：负责元数据管理，集群选举。&lt;!-- raw HTML omitted --&gt;目前最新版3.1.0提供了KRaft模式，集群不再依赖ZK。&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ZK主要负责存储Kafka集群的元数据，协调集群工作。&lt;/li&gt;&#xA;&lt;li&gt;记录信息如下：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;/brokers/ids/{0-n}：记录broker服务器节点，不同的broker使用不同的brokerid，会将自己的ip地址和端口信息记录到节点&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;/brokers/topics/{topic}：记录topic分区以及broker的对应信息&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;ol start=&#34;3&#34;&gt;&#xA;&lt;li&gt;/comsumers/{group_id}/ids/{consumer_id}：消费者负载均衡&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Topic：&lt;strong&gt;逻辑概念&lt;/strong&gt;，Kafka中消息以topic为单位进行分类，生产者将消息发送到特定的topic，消费者订阅topic进行消费。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;分区partition&#34;&gt;分区（partition）&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Partition：topic可以分为多个partition，分区在物理存储层面可以看作一个可Append的Log文件，消息被Append到Log中会分配一个&lt;code&gt;offset&lt;/code&gt;，这个属性是消息的唯一标识 ，&lt;strong&gt;Kafka通过它来保证消息在分区内的顺序性&lt;/strong&gt;，因此Kafka&lt;strong&gt;保证分区有序&lt;/strong&gt;而不是主题有序。&#xA;&lt;ul&gt;&#xA;&lt;li&gt;主题中的partition可以分布在不同的Broker中。&lt;/li&gt;&#xA;&lt;li&gt;消息到达broker后，根据分区规则存储到指定的partition。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;多副本机制replica&#34;&gt;多副本机制（Replica）&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;多副本机制（Replica）：是对于&lt;strong&gt;分区&lt;/strong&gt;而言的，&lt;strong&gt;同一分区的不同副本中保存的是相同的消息。&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Leader：分区中的主副本，负责处理读写请求，Producer/Consumer交互的对象。&lt;/li&gt;&#xA;&lt;li&gt;Follower：分区中的从副本，只会实时从Leader副本同步数据。&lt;/li&gt;&#xA;&lt;li&gt;所有副本被称为AR（Assigned Replicas），所有与Leader副本数据一致性差距过多的副本组成OSR（Out-of-Sync Replicas），于leader保持一定程度同步的副本称为ISR（In-Sync Replicas）。&lt;/li&gt;&#xA;&lt;li&gt;Leader故障后，从ISR中选举新的Leader。&lt;/li&gt;&#xA;&lt;li&gt;高水位（HW-High Watermark）：消费者能消费的最大offset位置，相当于&lt;strong&gt;所有副本中都存在的消息&lt;/strong&gt;（木桶效应）&lt;/li&gt;&#xA;&lt;li&gt;LEO（Log End Offset）：标识当前日志文件中下一条待写入消息的offset，每个副本都会维护自身的LEO，&lt;strong&gt;ISR中最小的LEO即为分区的HW&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;多副本的作用：提高Kafka的可用性。&lt;/p&gt;&#xA;&lt;p&gt;涉及参数：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;unclean.leader.election.enable：为true则ISR为空也能选举，为false则只能从ISR选举。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;metadata&#34;&gt;metadata&lt;/h3&gt;&#xA;&lt;p&gt;Q：客户端如何知道请求哪个broker？&lt;/p&gt;&#xA;&lt;p&gt;client通过metadata从任意broker获取集群信息，其中包括：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;topic信息&lt;/li&gt;&#xA;&lt;li&gt;每个topic的分区、副本情况&lt;/li&gt;&#xA;&lt;li&gt;leader分区所在的broker连接信息&lt;/li&gt;&#xA;&lt;li&gt;每个broker的连接信息&lt;/li&gt;&#xA;&lt;li&gt;其他信息&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://blog-1251613845.cos.ap-shanghai.myqcloud.com/20230718224608.png&#34; alt=&#34;Kafka应用架构(https://developer.confluent.io/courses/architecture/get-started/)&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;部署&#34;&gt;部署&lt;/h2&gt;&#xA;&lt;p&gt;使用WSL 2环境进行单机部署。&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;zero@Pluto:~$ uname -a&#xA;Linux Pluto 4.19.128-microsoft-standard #1 SMP Tue Jun 23 12:58:10 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Kafka需要Java环境，由于Kafka最新版本3.1.0不再支持Java8，故使用Java11。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
