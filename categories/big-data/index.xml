<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Big Data on l1nker4&#39;s Blog</title>
    <link>http://localhost:1313/categories/big-data/</link>
    <description>Recent content in Big Data on l1nker4&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 12 Nov 2024 15:37:52 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/big-data/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Spark入门</title>
      <link>http://localhost:1313/posts/big-data/spark-start/</link>
      <pubDate>Tue, 12 Nov 2024 15:37:52 +0800</pubDate>
      <guid>http://localhost:1313/posts/big-data/spark-start/</guid>
      <description>&lt;h2 id=&#34;简介&#34;&gt;简介&lt;/h2&gt;&#xA;&lt;p&gt;Apache Spark是一个分布式计算系统，具备以下特点：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;使用RDD(Resilient Distributed Datasets)，提供了比MapReduce更为丰富的模型&lt;/li&gt;&#xA;&lt;li&gt;基于内存计算，性能比MapReduce模型高&lt;/li&gt;&#xA;&lt;li&gt;集成离线计算、实时计算、机器学习、图计算等模块&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;核心模块：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Spark Core：提供Spark核心功能，是SQL、Streaming等模块实现的基础。&lt;/li&gt;&#xA;&lt;li&gt;Spark SQL：提供SQL进行数据查询的组件&lt;/li&gt;&#xA;&lt;li&gt;Spark Streaming：提供流式计算的组件&lt;/li&gt;&#xA;&lt;li&gt;MLlib：Spark平台的机器学习算法库&lt;/li&gt;&#xA;&lt;li&gt;GraphX：面向图计算的组件&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Spark名词解释：&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;&lt;strong&gt;名称&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;含义&lt;/strong&gt;&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Application&lt;/td&gt;&#xA;          &lt;td&gt;指用户提交的 Spark 应用程序&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Job&lt;/td&gt;&#xA;          &lt;td&gt;指 Spark 作业，是 Application 的子集，由行动算子（action）触发&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Stage&lt;/td&gt;&#xA;          &lt;td&gt;指 Spark 阶段，是 Job 的子集，以 RDD 的宽依赖为界&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Task&lt;/td&gt;&#xA;          &lt;td&gt;指 Spark 任务，是 Stage 的子集，Spark 中最基本的任务执行单元，对应单个线程，会被封装成 TaskDescription 对象提交到 Executor 的线程池中执行&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Driver&lt;/td&gt;&#xA;          &lt;td&gt;运行用户程序&lt;code&gt;main()&lt;/code&gt;方法并创建SparkContext的实例&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Cluster Manager&lt;/td&gt;&#xA;          &lt;td&gt;集群管理器，例如Yarn、Mesos、Kubernetes等&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;img src=&#34;https://blog-1251613845.cos.ap-shanghai.myqcloud.com/20240729135117.png&#34; alt=&#34;image.png&#34;&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;Spark运行过程：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Driver执行用户程序的main方法，并创建SparkContext，与Cluster Manager建立连接。&lt;/li&gt;&#xA;&lt;li&gt;Cluster Manager为用户程序分配计算资源，返回可使用的Executor列表。&lt;/li&gt;&#xA;&lt;li&gt;获取Executor资源后，Spark会将用户程序代码以及依赖包，发送给Executor&lt;/li&gt;&#xA;&lt;li&gt;SparkContext发送task到Executor，由executor执行计算任务。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;demo&#34;&gt;Demo&lt;/h3&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.spark&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;spark-core_2.12&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;3.1.2&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;scope&amp;gt;&lt;/span&gt;provided&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;/scope&amp;gt;&lt;/span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; org.apache.spark.SparkConf;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; org.apache.spark.api.java.JavaPairRDD;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; org.apache.spark.api.java.JavaRDD;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; org.apache.spark.api.java.JavaSparkContext;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; scala.Tuple2;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; java.util.Arrays;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;WordCountDemo&lt;/span&gt; {  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;private&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;static&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;wordCount&lt;/span&gt;(String fileName) {  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        SparkConf sparkConf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;new&lt;/span&gt; SparkConf().&lt;span style=&#34;color:#a6e22e&#34;&gt;setMaster&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;local&amp;#34;&lt;/span&gt;).&lt;span style=&#34;color:#a6e22e&#34;&gt;setAppName&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;JD Word Counter&amp;#34;&lt;/span&gt;);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        JavaSparkContext sparkContext &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;new&lt;/span&gt; JavaSparkContext(sparkConf);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        JavaRDD&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;String&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; inputFile &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sparkContext.&lt;span style=&#34;color:#a6e22e&#34;&gt;textFile&lt;/span&gt;(fileName);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        JavaRDD&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;String&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; wordsFromFile &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; inputFile.&lt;span style=&#34;color:#a6e22e&#34;&gt;flatMap&lt;/span&gt;(content &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; Arrays.&lt;span style=&#34;color:#a6e22e&#34;&gt;asList&lt;/span&gt;(content.&lt;span style=&#34;color:#a6e22e&#34;&gt;split&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;)).&lt;span style=&#34;color:#a6e22e&#34;&gt;iterator&lt;/span&gt;());  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        JavaPairRDD countData &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; wordsFromFile.&lt;span style=&#34;color:#a6e22e&#34;&gt;mapToPair&lt;/span&gt;(t &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;new&lt;/span&gt; Tuple2(t, 1)).&lt;span style=&#34;color:#a6e22e&#34;&gt;reduceByKey&lt;/span&gt;((x, y) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt;) x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt;) y);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        countData.&lt;span style=&#34;color:#a6e22e&#34;&gt;saveAsTextFile&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;CountData&amp;#34;&lt;/span&gt;);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;static&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt;(String&lt;span style=&#34;color:#f92672&#34;&gt;[]&lt;/span&gt; args) {  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (args.&lt;span style=&#34;color:#a6e22e&#34;&gt;length&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; 0) {  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            System.&lt;span style=&#34;color:#a6e22e&#34;&gt;out&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;println&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;No files provided.&amp;#34;&lt;/span&gt;);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            System.&lt;span style=&#34;color:#a6e22e&#34;&gt;exit&lt;/span&gt;(0);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        }  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        wordCount(args&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;);  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;提交应用：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Flink入门</title>
      <link>http://localhost:1313/posts/big-data/flink-start/</link>
      <pubDate>Fri, 11 Oct 2024 21:37:41 +0800</pubDate>
      <guid>http://localhost:1313/posts/big-data/flink-start/</guid>
      <description>&lt;h1 id=&#34;简介&#34;&gt;简介&lt;/h1&gt;&#xA;&lt;p&gt;Apache Flink是一个用于有状态的并行数据流的分布式计算系统，同时支持流式处理和批量处理。&lt;/p&gt;&#xA;&lt;p&gt;实际数据分析应用都是面向无限数据流，三类通常使用有状态流处理实现的应用程序：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;事件驱动应用程序：使用特定的业务逻辑来提取事件流并处理事件。&#xA;&lt;ol&gt;&#xA;&lt;li&gt;实时推荐、行为模式检测、异常检测&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;数据管道应用程序：将数据从A组件复制到B组件的ETL流程，pipeline包括多个源（source）和接收器（sink）。&#xA;3. 实时数据仓库：数据实时清洗、归并、结构化&lt;/li&gt;&#xA;&lt;li&gt;数据流式分析应用程序：连续地提取事件流数据，并计算出最新结果并存储，用于查询。&#xA;&lt;ol&gt;&#xA;&lt;li&gt;用户行为等实时数据分析&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;常见的流式处理框架对比：&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;&lt;/th&gt;&#xA;          &lt;th&gt;Flink&lt;/th&gt;&#xA;          &lt;th&gt;Spark Streaming&lt;/th&gt;&#xA;          &lt;th&gt;Apache Storm&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;架构&lt;/td&gt;&#xA;          &lt;td&gt;主从模式&lt;/td&gt;&#xA;          &lt;td&gt;主从模式，依赖Spark，每个Batch处理都依赖主节点&lt;/td&gt;&#xA;          &lt;td&gt;主从模式，依赖ZK&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;处理方式&lt;/td&gt;&#xA;          &lt;td&gt;Native&lt;/td&gt;&#xA;          &lt;td&gt;Micro-Batch&lt;/td&gt;&#xA;          &lt;td&gt;Native&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;容错&lt;/td&gt;&#xA;          &lt;td&gt;基于Chandy-Lamport distributed snapshots checkpoint机制&lt;/td&gt;&#xA;          &lt;td&gt;WAL与RDD机制&lt;/td&gt;&#xA;          &lt;td&gt;Record&amp;rsquo;s ACK&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;处理模式&lt;/td&gt;&#xA;          &lt;td&gt;单条事件处理、时间窗口划分的所有事件&lt;/td&gt;&#xA;          &lt;td&gt;时间窗口内的所有时间&lt;/td&gt;&#xA;          &lt;td&gt;单条事件处理&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;数据保证&lt;/td&gt;&#xA;          &lt;td&gt;exactly once&lt;/td&gt;&#xA;          &lt;td&gt;exactly once&lt;/td&gt;&#xA;          &lt;td&gt;at least once&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;API支持&lt;/td&gt;&#xA;          &lt;td&gt;high&lt;/td&gt;&#xA;          &lt;td&gt;high&lt;/td&gt;&#xA;          &lt;td&gt;low&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;社区活跃度&lt;/td&gt;&#xA;          &lt;td&gt;high&lt;/td&gt;&#xA;          &lt;td&gt;high&lt;/td&gt;&#xA;          &lt;td&gt;medium&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;部署性&lt;/td&gt;&#xA;          &lt;td&gt;部署简单，仅依赖JRE&lt;/td&gt;&#xA;          &lt;td&gt;部署简单，仅依赖JRE&lt;/td&gt;&#xA;          &lt;td&gt;依赖JRE和Zookeeper&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;Flink优点：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;毫秒级延迟&lt;/li&gt;&#xA;&lt;li&gt;统一数据处理组件栈，可以处理不同类型的数据需求&lt;/li&gt;&#xA;&lt;li&gt;支持事件时间、接入时间、处理时间等概念&lt;/li&gt;&#xA;&lt;li&gt;基于轻量级分布式快照实现的容错&lt;/li&gt;&#xA;&lt;li&gt;支持有状态计算，灵活的state-backend（HDFS、内存、RocksDB）&lt;/li&gt;&#xA;&lt;li&gt;满足Exactly-once需求&lt;/li&gt;&#xA;&lt;li&gt;支持高度灵活的window操作&lt;/li&gt;&#xA;&lt;li&gt;带反压的连续流模型&lt;/li&gt;&#xA;&lt;li&gt;每秒千万级吞吐量&lt;/li&gt;&#xA;&lt;li&gt;易用性：提供了SQL、Table API、Stream API等方式&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;流式计算的时间窗口，涉及处理时间和事件时间，主要有以下区别：&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
